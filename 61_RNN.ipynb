{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "61_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYiRsFGD6iUC"
      },
      "source": [
        "# 0 TorchText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset Preview\n",
        "\n",
        "Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. \n",
        "\n",
        "We will be using previous session tweet dataset. Let's just preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DwDRwcdcOTHf",
        "outputId": "c72e147a-e125-4222-a500-427ca69b3057"
      },
      "source": [
        "upoaded=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f34f63de-2534-4f4c-bc61-2527d246bafa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f34f63de-2534-4f4c-bc61-2527d246bafa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving tweets.csv to tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675b8d13-234a-484c-bf4c-8e54747967a9"
      },
      "source": [
        "df=pd.read_csv('tweets.csv')\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07ca27b-c00b-4b75-ab36-2603f65f539f"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de9dabb-33c4-4701-c5c3-8f7024e1b7f2"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f87c5bb3690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6aPdyLBtjEd"
      },
      "source": [
        "Here while definign the Tweet, below, inlcude_lengths is kept False is its not needed. We are not creating a padded sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=False)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nfZ3bG7IAQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training, testing, and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmKkoIO8vEO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542ef210-baa5-4256-98c5-309ef470a382"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kix8P2IKSBaV"
      },
      "source": [
        "An example from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy-t3FMUy6Zr",
        "outputId": "09762113-0589-4a67-f829-5847616cc208"
      },
      "source": [
        "train.examples[10].tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Obama',\n",
              " ',',\n",
              " 'Romney',\n",
              " 'agree',\n",
              " ':',\n",
              " 'Admit',\n",
              " 'women',\n",
              " 'to',\n",
              " 'Augusta',\n",
              " 'golf',\n",
              " 'club',\n",
              " ':',\n",
              " 'US',\n",
              " 'President',\n",
              " 'Barack',\n",
              " 'Obama',\n",
              " 'believes',\n",
              " 'women',\n",
              " 'should',\n",
              " 'be',\n",
              " 'allowe',\n",
              " '...',\n",
              " 'http://t.co/PVKrepqI']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b7c9f6-1fab-47fa-9fd7-05407ab7ef60"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabu‐ lary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. \n",
        "\n",
        "Let’s limit the vocabulary to a maximum of 5000 words in our training set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyEeEjXTGhX"
      },
      "source": [
        "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eeb24f4-924b-4fa8-e943-4114d9f415bb"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwjD2-ebTeUX"
      },
      "source": [
        "**Lots of stopwords!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PED4HJWH4t"
      },
      "source": [
        "We use the Embedding and RNN modules in PyTorch to build a simple model for classifying tweets.\n",
        "\n",
        "In this model we create three layers. \n",
        "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
        "2. That’s then fed into an RNN layer with 100 hidden features (again, we’re compressing down from the 300-dimensional ).\n",
        "3. Finally, the output of the RNN (the final hidden state after processing the incoming tweet) is pushed through another RNN which takes the output of previous RNN and its own state and outputs a single vectore which is then pushed to  standard fully connected layer with three outputs to correspond to our three possible classes (negative, positive, or neutral)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1):\n",
        "        \n",
        "        super().__init__()          \n",
        "        self.hidden_dim=hidden_dim\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "              \n",
        "        # RNN layer for encoding\n",
        "        self.encoder = nn.RNN(embedding_dim,hidden_dim,batch_first=True)\n",
        "        # RNN layer for decoding\n",
        "        self.decoder=nn.RNN(hidden_dim,hidden_dim,batch_first=True)\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        # text = [batchsize, sent_length]\n",
        "        # embedded = [batchsize, sent_len, embedding_dim]\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "       \n",
        "        #Initialize the first hidden state\n",
        "        hidden=torch.zeros(1,text.size(0),self.hidden_dim).to(device)\n",
        "\n",
        "        output1, hidden = self.encoder(embedded,hidden)\n",
        "\n",
        "        #hidden = [batchsize, 1,hidden_dim] as number of layers taken here is 1\n",
        "        #The first hidden state which goes to encoder is the last single vector from the encoder. \n",
        "        #The output1 of encoder is of shape [batchsize, sent_len, hiddenn_dim], contains hidden states from each time_step \n",
        "        # and that goes as the input to the decoder RNN along with the final single vector from encoder (final hidden state)\n",
        "\n",
        "        hidden1=hidden #final hidden vector from encoder RNN goes to first cell of decoder along with first output of encoder.\n",
        "        output2,hidden1=self.decoder(output1,hidden1)\n",
        "\n",
        "        #The output2 of decoder is of shape [batchsize, sent_len, hiddenn_dim], contains hidden states from each time_step \n",
        "        #hidden1 contains the last output and is sent to fully connected layer to make the final prediction.\n",
        "        dense_outputs = self.fc(hidden1)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "        \n",
        "        #Since we want to output at each time step of encoder and decoder, return output1 and output2 as well along with prediction(output)\n",
        "            \n",
        "        return output,output1,output2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673e91c1-67a7-4abd-a855-cc3afa1f7307"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): RNN(300, 100, batch_first=True)\n",
            "  (decoder): RNN(100, 100, batch_first=True)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,456,003 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe1Fpqcsr4Rx"
      },
      "source": [
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxykFvQVr-oL"
      },
      "source": [
        "##Trials to understand the shapes of the output\n",
        "Next few cells can be ignored as they were the trials to understand the shape and outputs of the model to be able to capture what is expected from the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E473neRS-cd7"
      },
      "source": [
        "b=next(iter(train_iterator))\n",
        "t,l=b\n",
        "l.size,size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GijbQy2KnNP"
      },
      "source": [
        "emb=nn.Embedding(size_of_vocab,embedding_dim).to(device)\n",
        "#tt=t[0] as include length is switched off this is not needed.\n",
        "te=emb(t)\n",
        "te.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaNxjB05-vgd"
      },
      "source": [
        "pred,o1,o2,h,h1=model(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URzoSUoEFQHQ",
        "outputId": "19281864-7cde-4875-b7b8-c10b789182c2"
      },
      "source": [
        "o1.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfyP6sY4FSs0",
        "outputId": "f58abfa9-b753-4dff-eeba-3c1867dd2438"
      },
      "source": [
        "o2.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 20, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQfd5hOYFWIm",
        "outputId": "0bd6aec1-f298-4910-8219-25ff2e93f7c2"
      },
      "source": [
        "h.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daQnKxZLFYhL",
        "outputId": "bb084e19-9536-46ec-ebcc-a8a3233323dc"
      },
      "source": [
        "h1.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vea_2C0YmZ1u"
      },
      "source": [
        "assert torch.equal(o1[:,-1,:],h1.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdUBK2auAR-0"
      },
      "source": [
        "loss=criterion(pred, b.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5htg_lpEAhdX",
        "outputId": "17a678e9-0866-40dc-879b-665b71b92f6d"
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0855475664138794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKy1juNOAo7j"
      },
      "source": [
        "loss.backward()\n",
        "optimizer.step()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukE6m1jFtKTn"
      },
      "source": [
        "This training loop is same taken from the notebook developed in the class on tweets data set, with suitable modifications to capture the hidden state at every time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WjEPLKsAiS_"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text\n",
        "        tweet = batch.tweets   \n",
        "        \n",
        "        #Capture predictions and output of encode and decoder at every time step.\n",
        "        #Although it is not needed while training it is captured to maintain consistency across.\n",
        "\n",
        "        predictions,o1,o2= model(tweet)\n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)   \n",
        "\n",
        "        #As the model is overfitting to the training data, regularisation is introduced.     \n",
        "        L2_lambda=0.001\n",
        "        L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())    \n",
        "        loss=loss+L2_lambda*L2_norm    \n",
        "\n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZcHhkkvAsCt"
      },
      "source": [
        "**Evaluation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet = batch.tweets\n",
        "            \n",
        "            predictions,o1,o2= model(tweet)\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            L2_lambda=0.001\n",
        "            L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())    \n",
        "            loss=loss+L2_lambda*L2_norm    \n",
        "        \n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1aa1737-2a06-4e63-96d4-92e86e0926c7"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_valid_acc= valid_acc\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')\n",
        "print(f'\\t best Val. Loss: {best_valid_loss:.3f} |  best Val. Acc: {best_valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1390.183 | Train Acc: 57.00%\n",
            "\t Val. Loss: 1381.698 |  Val. Acc: 64.73% \n",
            "\n",
            "\tTrain Loss: 1373.775 | Train Acc: 69.88%\n",
            "\t Val. Loss: 1365.462 |  Val. Acc: 67.86% \n",
            "\n",
            "\tTrain Loss: 1357.645 | Train Acc: 71.40%\n",
            "\t Val. Loss: 1349.476 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1341.753 | Train Acc: 72.08%\n",
            "\t Val. Loss: 1333.711 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 1326.076 | Train Acc: 73.43%\n",
            "\t Val. Loss: 1318.152 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 1310.613 | Train Acc: 73.52%\n",
            "\t Val. Loss: 1302.789 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 1295.334 | Train Acc: 75.37%\n",
            "\t Val. Loss: 1287.622 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 1280.247 | Train Acc: 77.99%\n",
            "\t Val. Loss: 1272.641 |  Val. Acc: 68.75% \n",
            "\n",
            "\tTrain Loss: 1265.356 | Train Acc: 79.68%\n",
            "\t Val. Loss: 1257.849 |  Val. Acc: 72.32% \n",
            "\n",
            "\tTrain Loss: 1250.653 | Train Acc: 80.69%\n",
            "\t Val. Loss: 1243.248 |  Val. Acc: 72.32% \n",
            "\n",
            "\tTrain Loss: 1236.140 | Train Acc: 81.71%\n",
            "\t Val. Loss: 1228.833 |  Val. Acc: 72.32% \n",
            "\n",
            "\tTrain Loss: 1221.807 | Train Acc: 82.47%\n",
            "\t Val. Loss: 1214.602 |  Val. Acc: 72.77% \n",
            "\n",
            "\tTrain Loss: 1207.653 | Train Acc: 82.89%\n",
            "\t Val. Loss: 1200.544 |  Val. Acc: 72.32% \n",
            "\n",
            "\tTrain Loss: 1193.675 | Train Acc: 83.23%\n",
            "\t Val. Loss: 1186.652 |  Val. Acc: 73.21% \n",
            "\n",
            "\tTrain Loss: 1179.866 | Train Acc: 83.57%\n",
            "\t Val. Loss: 1172.930 |  Val. Acc: 73.21% \n",
            "\n",
            "\tTrain Loss: 1166.221 | Train Acc: 83.90%\n",
            "\t Val. Loss: 1159.382 |  Val. Acc: 73.21% \n",
            "\n",
            "\tTrain Loss: 1152.744 | Train Acc: 84.24%\n",
            "\t Val. Loss: 1145.986 |  Val. Acc: 73.21% \n",
            "\n",
            "\tTrain Loss: 1139.426 | Train Acc: 84.83%\n",
            "\t Val. Loss: 1132.752 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 1126.268 | Train Acc: 84.75%\n",
            "\t Val. Loss: 1119.674 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 1113.265 | Train Acc: 84.83%\n",
            "\t Val. Loss: 1106.743 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 1100.416 | Train Acc: 85.00%\n",
            "\t Val. Loss: 1093.976 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 1087.716 | Train Acc: 85.17%\n",
            "\t Val. Loss: 1081.348 |  Val. Acc: 75.00% \n",
            "\n",
            "\tTrain Loss: 1075.164 | Train Acc: 85.34%\n",
            "\t Val. Loss: 1068.880 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 1062.757 | Train Acc: 85.51%\n",
            "\t Val. Loss: 1056.549 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 1050.493 | Train Acc: 85.93%\n",
            "\t Val. Loss: 1044.357 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 1038.371 | Train Acc: 86.18%\n",
            "\t Val. Loss: 1032.307 |  Val. Acc: 75.00% \n",
            "\n",
            "\tTrain Loss: 1026.389 | Train Acc: 86.18%\n",
            "\t Val. Loss: 1020.392 |  Val. Acc: 75.45% \n",
            "\n",
            "\tTrain Loss: 1014.539 | Train Acc: 87.37%\n",
            "\t Val. Loss: 1008.622 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 1002.830 | Train Acc: 87.11%\n",
            "\t Val. Loss: 996.981 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 991.256 | Train Acc: 86.78%\n",
            "\t Val. Loss: 985.474 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 979.805 | Train Acc: 87.11%\n",
            "\t Val. Loss: 974.082 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 968.485 | Train Acc: 87.45%\n",
            "\t Val. Loss: 962.830 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 957.293 | Train Acc: 87.45%\n",
            "\t Val. Loss: 951.697 |  Val. Acc: 76.34% \n",
            "\n",
            "\tTrain Loss: 946.227 | Train Acc: 87.45%\n",
            "\t Val. Loss: 940.711 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 935.282 | Train Acc: 87.87%\n",
            "\t Val. Loss: 929.826 |  Val. Acc: 75.00% \n",
            "\n",
            "\tTrain Loss: 924.457 | Train Acc: 88.21%\n",
            "\t Val. Loss: 919.066 |  Val. Acc: 75.45% \n",
            "\n",
            "\tTrain Loss: 913.754 | Train Acc: 88.80%\n",
            "\t Val. Loss: 908.428 |  Val. Acc: 75.00% \n",
            "\n",
            "\tTrain Loss: 903.169 | Train Acc: 88.89%\n",
            "\t Val. Loss: 897.906 |  Val. Acc: 75.45% \n",
            "\n",
            "\tTrain Loss: 892.701 | Train Acc: 89.06%\n",
            "\t Val. Loss: 887.491 |  Val. Acc: 76.34% \n",
            "\n",
            "\tTrain Loss: 882.351 | Train Acc: 88.80%\n",
            "\t Val. Loss: 877.198 |  Val. Acc: 76.34% \n",
            "\n",
            "\tTrain Loss: 872.110 | Train Acc: 88.97%\n",
            "\t Val. Loss: 867.023 |  Val. Acc: 76.34% \n",
            "\n",
            "\tTrain Loss: 861.983 | Train Acc: 88.97%\n",
            "\t Val. Loss: 856.962 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 851.968 | Train Acc: 88.97%\n",
            "\t Val. Loss: 847.005 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 842.060 | Train Acc: 89.06%\n",
            "\t Val. Loss: 837.151 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 832.258 | Train Acc: 89.31%\n",
            "\t Val. Loss: 827.411 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 822.565 | Train Acc: 89.39%\n",
            "\t Val. Loss: 817.768 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 812.978 | Train Acc: 89.39%\n",
            "\t Val. Loss: 808.236 |  Val. Acc: 74.11% \n",
            "\n",
            "\tTrain Loss: 803.490 | Train Acc: 89.65%\n",
            "\t Val. Loss: 798.797 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 794.109 | Train Acc: 89.56%\n",
            "\t Val. Loss: 789.475 |  Val. Acc: 73.66% \n",
            "\n",
            "\tTrain Loss: 784.825 | Train Acc: 89.73%\n",
            "\t Val. Loss: 780.248 |  Val. Acc: 73.21% \n",
            "\n",
            "\t best Val. Loss: 780.248 |  best Val. Acc: 73.21% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZgzB0ZkHVTI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZfnWo0abRx"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    #tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tweet]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction,o1,o2= model(tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN5av2Zxx4Mh",
        "outputId": "ac796804-72b1-46a6-ebf8-100728e11ff7"
      },
      "source": [
        "import random\n",
        "for i in range(10):\n",
        "  r_n=random.choice(train)\n",
        "  tweet=r_n.tweets\n",
        "  #print(r_n)\n",
        "  p=classify_tweet(tweet)\n",
        "  print(f'{tweet} | sentiment : {p}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@KatrinaNation', 'Katrina', 'I', 'just', 'seen', 'the', 'HBO', 'documentary', 'hot', 'coffee', '.', 'I', 'feel', 'so', 'upset', ',', 'we', 'need', 'four', 'more', 'years', 'of', 'President', 'Obama', '1000', '%', 'certtain'] | sentiment : Negative\n",
            "['For', '$', '10', 'I', \"'d\", 'prank', 'call', 'Obama'] | sentiment : Negative\n",
            "['RT', '@Notintheface1', ':', 'Apparently', ',', 'Romney', \"'s\", 'entire', 'campaign', 'strategy', 'for', 'Obama', 'consists', 'of', '\"', 'I', 'Know', 'You', 'Are', 'But', 'What', 'Am', 'I', '?', '\"'] | sentiment : Negative\n",
            "['RT', '@markknoller', ':', 'AT', 'a', 'campaign', 'fundraiser', 'tonight', ',', 'Pres', '.', 'Obama', 'again', 'denounced', 'Mitt', 'Romney', 'by', 'name', 'for', 'his', 'support', 'of', 'the', 'House', '-', 'passed', 'GOP', 'Budget', '.'] | sentiment : Positive\n",
            "['@HesDanTheMan', '@edshow', 'nothing', 'will', 'come', 'of', 'it', '.', ' ', 'Had', 'it', 'been', '#', 'obama', ',', 'the', '#', 'gop', 'would', 'impeach', 'him', '.', '#', 'p2', '#', 'edshow'] | sentiment : Negative\n",
            "['RT', '@jmimac351', ':', '@EWErickson', '$', '4', 'gas', ',', 'high', 'unemployment', '&', 'Obama', 'is', 'worried', 'about', 'Augusta', 'National', '.', 'This', 'is', 'smoke', 'and', 'mirrors', 'for', 'utter', 'failure', '.', '#', 'cantwait2vote'] | sentiment : Negative\n",
            "['RT', '@RealNichelle', ':', 'I', 'love', 'that', 'even', 'most', 'that', 'do', \"n't\", 'agree', 'with', 'Pres', 'Obama', \"'s\", 'politics', 'could', 'appreciate', 'that', 'he', \"'s\", 'a', 'Trekker', '.', 'That', \"'s\", 'what', 'IDIC', 'is', 'all', 'about', '.'] | sentiment : Negative\n",
            "['RT', '@jmimac351', ':', '@EWErickson', '$', '4', 'gas', ',', 'high', 'unemployment', '&', 'Obama', 'is', 'worried', 'about', 'Augusta', 'National', '.', 'This', 'is', 'smoke', 'and', 'mirrors', 'for', 'utter', 'failure', '.', '#', 'cantwait2vote'] | sentiment : Negative\n",
            "['Not', 'good', 'for', 'the', 'D', 'Party', '.', 'http://t.co/wJVdoGyI'] | sentiment : Positive\n",
            "['#', 'WhatsRomneyHiding', '?', ' ', 'less', 'than', 'how', 'much', 'Obama', \"'s\", 'hiding', 'from', 'the', 'public', '.', ' ', 'That', \"'s\", 'what', '.'] | sentiment : Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZBMtzFK0Wpl"
      },
      "source": [
        "This is where actual assignment starts wher we have to output the hidden states at every step of the encoder and decoder for a randomly chsen sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr_yA7fF0iP0"
      },
      "source": [
        "r_n=random.choice(train)\n",
        "tweet=r_n.tweets\n",
        "indexed = [tokenizer[t] for t in tweet]        \n",
        "# compute no. of words        \n",
        "length = [len(indexed)]\n",
        "# convert to tensor                                    \n",
        "tensor = torch.LongTensor(indexed).to(device)   \n",
        "# reshape in form of batch, no. of words           \n",
        "tensor = tensor.unsqueeze(1).T  \n",
        "# convert to tensor                          \n",
        "length_tensor = torch.LongTensor(length)\n",
        "# Get the model prediction                  \n",
        "prediction,o1,o2= model(tensor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8PeU6s91459",
        "outputId": "e59d1182-9516-47da-d66a-57ce242dcdb7"
      },
      "source": [
        "prediction.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z59---5W2Bui",
        "outputId": "5e510409-f461-4aa0-a854-6ce75a8f9e85"
      },
      "source": [
        "o1.size(), o2.size(), len(tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 18, 100]), torch.Size([1, 18, 100]), 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqDEDEbh5Vr2"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_aGbjNr25YR"
      },
      "source": [
        "encoded=o1.squeeze()\n",
        "decoded=o2.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agNXjG5e3EcA",
        "outputId": "a3abcc5e-a3f0-4db9-c731-4c5743a1d5d2"
      },
      "source": [
        "encoded.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9PnZd6M3JvN",
        "outputId": "bf0ba669-554f-4783-8cc8-3ada2104487e"
      },
      "source": [
        "encoded[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSI8HZ_V2jj5"
      },
      "source": [
        "print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVnHit6w50eP",
        "outputId": "3714e1dc-1b81-43d8-e74e-91ea4cf77f4e"
      },
      "source": [
        "print(tweet, len(tweet))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['If', 'you', 'can', 'find', 'a', 'better', 'Obama', 'gif', 'than', 'this', 'one', ',', 'I', \"'m\", 'quitting', 'Twitter', '.', 'http://t.co/cNr0Sr3c'] 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgWp96jA2S38",
        "outputId": "a5ded0de-8e1f-41ff-980a-4c0245c5fd27"
      },
      "source": [
        "\n",
        "for i in range(len(tweet)):\n",
        "  enc=encoded[i]\n",
        "  dec=decoded[i]\n",
        "  print(f'word :{tweet[i]}  \\n encoded : {enc}\\n decoded : {dec}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word :If  \n",
            " encoded : tensor([-0.1219,  0.6393,  0.8072,  0.0501,  0.4938,  0.8374,  0.4365,  0.8921,\n",
            "         0.1255, -0.4568, -0.2770,  0.8646,  0.3292, -0.6725, -0.6538, -0.2788,\n",
            "        -0.8048,  0.1877,  0.0111,  0.0480,  0.2366, -0.6455, -0.2108,  0.1328,\n",
            "        -0.9034,  0.1650, -0.2463, -0.7071, -0.0422,  0.2194, -0.2699,  0.3182,\n",
            "        -0.0832, -0.2717,  0.9182, -0.0059, -0.2682, -0.0154, -0.0785, -0.1075,\n",
            "        -0.0830,  0.2120,  0.3154,  0.3100,  0.2673, -0.7040, -0.4662, -0.1212,\n",
            "        -0.5743, -0.1202, -0.6514, -0.5062, -0.6050,  0.3397,  0.1468,  0.3589,\n",
            "        -0.1300, -0.3899,  0.0020, -0.7171,  0.6364,  0.9270, -0.4000,  0.0403,\n",
            "         0.1271,  0.4519, -0.5121, -0.1553, -0.2712, -0.4041,  0.1343, -0.6136,\n",
            "        -0.0233,  0.7324,  0.2686, -0.3927, -0.8470,  0.4281, -0.3928,  0.1612,\n",
            "         0.1470, -0.3926, -0.9191,  0.0896,  0.4663, -0.3839, -0.4881, -0.3946,\n",
            "         0.6254, -0.8126,  0.3463,  0.6129,  0.5195, -0.4110, -0.8558, -0.8201,\n",
            "         0.1622,  0.7036, -0.4336, -0.3513], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.5437,  0.0383, -0.3279,  0.2949, -0.1450,  0.0987,  0.2612,  0.4076,\n",
            "        -0.1961, -0.0663, -0.0830, -0.4612, -0.1785, -0.7779, -0.5583, -0.0789,\n",
            "         0.1314,  0.2084, -0.0504,  0.3995,  0.1199,  0.2667,  0.1220,  0.0278,\n",
            "         0.2030,  0.0759, -0.3150,  0.0020,  0.3923,  0.7926, -0.3637, -0.2401,\n",
            "         0.2722, -0.3055,  0.2385, -0.4424, -0.1774,  0.0286,  0.4561, -0.0247,\n",
            "         0.0966, -0.0660, -0.2788, -0.2693, -0.0513,  0.0610, -0.4825, -0.1084,\n",
            "        -0.6115, -0.7144,  0.4428,  0.0269,  0.0408,  0.1634, -0.3795, -0.2691,\n",
            "        -0.0228, -0.2117,  0.0347,  0.0029, -0.0704,  0.2117,  0.3419,  0.1510,\n",
            "         0.1892,  0.3570, -0.0843,  0.6157, -0.0750,  0.0112,  0.1183, -0.2972,\n",
            "        -0.1793,  0.1035, -0.5913, -0.1324,  0.1301, -0.0809, -0.3907,  0.5775,\n",
            "         0.2897, -0.3606,  0.0246,  0.2384,  0.3432, -0.0376, -0.3496, -0.2048,\n",
            "        -0.6271,  0.3458,  0.5584,  0.0812,  0.5265,  0.2514, -0.3865, -0.0932,\n",
            "         0.5214, -0.1392,  0.0431, -0.1305], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :you  \n",
            " encoded : tensor([-1.0572e-01, -3.7647e-01,  3.2657e-01, -3.5636e-01,  9.0457e-01,\n",
            "         4.0293e-01,  4.3873e-02, -7.8502e-04, -1.2505e-01, -8.3551e-01,\n",
            "        -2.7817e-01, -4.5418e-01,  9.3950e-02, -6.1915e-01,  1.8105e-01,\n",
            "         6.9431e-01, -9.9216e-02, -6.1033e-01, -1.9728e-01, -3.1205e-01,\n",
            "        -2.3305e-02, -2.7295e-01, -3.8619e-01,  1.6137e-01, -1.1273e-01,\n",
            "        -9.9875e-02,  7.1203e-01, -6.9354e-01, -1.1544e-01, -6.9128e-01,\n",
            "        -1.9396e-01, -6.1614e-01, -2.2633e-01, -1.7881e-01, -5.7148e-01,\n",
            "         1.6126e-01, -1.6871e-01, -4.0793e-01,  1.3389e-01,  1.1343e-01,\n",
            "        -2.1418e-01,  2.0312e-01,  4.7358e-01,  8.9034e-01,  2.5283e-01,\n",
            "         2.0829e-01,  6.4986e-02, -3.1535e-01,  3.3407e-01, -3.2283e-01,\n",
            "         3.1269e-01, -4.1484e-01,  5.6208e-01, -2.1541e-01, -3.5599e-01,\n",
            "        -8.4784e-01,  2.1716e-01,  7.2174e-01, -8.5770e-01,  5.3887e-01,\n",
            "         4.0061e-01, -5.2669e-01,  5.7853e-01, -6.1632e-01,  4.1396e-01,\n",
            "        -6.3480e-02,  4.4993e-01,  7.8746e-01, -3.5854e-01,  9.3657e-01,\n",
            "        -6.2946e-01, -1.1047e-01, -2.9181e-01,  1.7137e-01, -2.5949e-01,\n",
            "        -7.1303e-01,  5.2795e-01,  5.0497e-01,  7.1533e-02, -3.0963e-01,\n",
            "         2.1272e-01, -2.6547e-01,  5.9918e-02,  3.9907e-01,  3.6491e-01,\n",
            "        -3.7211e-01, -7.9346e-03, -6.5765e-01,  1.4940e-01, -2.3073e-01,\n",
            "        -2.7782e-01,  8.0677e-02,  4.4341e-02, -2.9425e-02, -6.4145e-01,\n",
            "         3.4656e-01, -5.8405e-01,  1.4252e-02,  4.5337e-01, -4.5811e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.4573,  0.2999, -0.4054,  0.4770, -0.6636,  0.4931,  0.3105,  0.4907,\n",
            "         0.4723, -0.0937,  0.2241, -0.5600, -0.3405, -0.4493, -0.5284,  0.4143,\n",
            "         0.4678,  0.4093,  0.3581,  0.5879, -0.3268,  0.5900, -0.4143,  0.1581,\n",
            "         0.3902, -0.5939, -0.2399,  0.4108,  0.6678,  0.5972, -0.3806, -0.5536,\n",
            "         0.4412, -0.2240, -0.3693, -0.0448, -0.3333,  0.5577,  0.5306,  0.5598,\n",
            "        -0.1547, -0.0522, -0.4284,  0.5557, -0.4457,  0.7074, -0.3411, -0.0986,\n",
            "        -0.3233, -0.4842,  0.6732, -0.4131,  0.2323,  0.3417, -0.3913,  0.2104,\n",
            "         0.2048, -0.6056, -0.3345, -0.2114,  0.4815,  0.2809,  0.4551, -0.4787,\n",
            "         0.5314,  0.1434, -0.4937,  0.3944, -0.6117,  0.3905,  0.2528, -0.2639,\n",
            "        -0.5291,  0.5430, -0.5190,  0.1391,  0.2615, -0.5364, -0.4517,  0.6126,\n",
            "         0.4898, -0.4818, -0.3181,  0.3910,  0.3123,  0.2258,  0.3643, -0.5416,\n",
            "        -0.5187,  0.5111,  0.2672,  0.0851,  0.4248, -0.3758, -0.4103,  0.4912,\n",
            "         0.2148, -0.1776,  0.0645, -0.3273], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :can  \n",
            " encoded : tensor([ 0.0681, -0.6650, -0.6283,  0.3615,  0.7717, -0.1612, -0.0127,  0.1166,\n",
            "         0.2627, -0.1131,  0.7199, -0.5930,  0.1055, -0.8665,  0.1972,  0.3606,\n",
            "         0.2594, -0.5854,  0.0830,  0.0503,  0.0512,  0.6442,  0.1910, -0.3207,\n",
            "        -0.5356,  0.7881, -0.0802, -0.2810, -0.7868, -0.1775,  0.6608,  0.5175,\n",
            "        -0.3610, -0.5077, -0.1079,  0.3476,  0.8350,  0.8141, -0.5315, -0.1607,\n",
            "         0.3022,  0.0684, -0.2801, -0.2214,  0.3210,  0.3045,  0.7052,  0.4289,\n",
            "        -0.5490,  0.7315,  0.2246,  0.6036, -0.3997,  0.1772, -0.0328, -0.0533,\n",
            "         0.5577,  0.3216, -0.5568,  0.5326,  0.0864, -0.7288, -0.0677, -0.6635,\n",
            "         0.8309,  0.5616, -0.0994,  0.5845,  0.7983,  0.6236, -0.7428, -0.2486,\n",
            "        -0.0215,  0.3738, -0.1551, -0.6918,  0.1744, -0.0028, -0.3482,  0.0135,\n",
            "         0.0443,  0.6011, -0.6631,  0.3869, -0.3823,  0.1600, -0.1454, -0.8150,\n",
            "        -0.2671,  0.0138,  0.3457,  0.7635, -0.0218,  0.3745,  0.1558, -0.7088,\n",
            "         0.0689, -0.3132, -0.4244,  0.3341], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.6543,  0.4817, -0.4280,  0.7272, -0.6724,  0.6638,  0.6788,  0.6211,\n",
            "         0.6266, -0.3154,  0.2391, -0.7510, -0.3888, -0.8062, -0.6425,  0.6101,\n",
            "         0.6110,  0.7079,  0.6075,  0.7648, -0.6080,  0.6947, -0.5799,  0.3990,\n",
            "         0.3168, -0.6746,  0.3500,  0.7653,  0.6692,  0.8610, -0.5898, -0.6782,\n",
            "         0.5378, -0.6995, -0.7738, -0.5139, -0.5597,  0.5204,  0.4997,  0.7247,\n",
            "        -0.3977,  0.2213, -0.5362,  0.6343, -0.8510,  0.6550, -0.4046, -0.1169,\n",
            "        -0.5246, -0.5306,  0.6988, -0.7289,  0.4137,  0.4912, -0.7086,  0.3483,\n",
            "         0.0349, -0.7846, -0.3654, -0.2953,  0.5700, -0.3229,  0.6395, -0.3998,\n",
            "         0.7072, -0.2761, -0.6773,  0.5807, -0.7398,  0.7928,  0.6471, -0.2437,\n",
            "        -0.6960,  0.7130, -0.6565,  0.2863,  0.5766, -0.4848, -0.4799,  0.8155,\n",
            "         0.5964, -0.7633, -0.5283,  0.5751,  0.5727, -0.1449,  0.5604, -0.7460,\n",
            "        -0.7100,  0.6227,  0.3886,  0.3116,  0.4895, -0.6253, -0.5768,  0.8374,\n",
            "         0.3509, -0.5434, -0.3836, -0.3906], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :find  \n",
            " encoded : tensor([ 0.1119,  0.7164,  0.5444,  0.4087, -0.3579, -0.7713,  0.3836, -0.1737,\n",
            "         0.1183, -0.7177,  0.8714, -0.3031,  0.2186,  0.0395,  0.1649,  0.0676,\n",
            "        -0.4580,  0.2352, -0.6474, -0.5322,  0.8039,  0.1503, -0.5370,  0.3631,\n",
            "        -0.1163, -0.2312,  0.2122,  0.6915, -0.5671, -0.6410, -0.1070, -0.1034,\n",
            "        -0.6538, -0.6324,  0.7472,  0.1781,  0.3986,  0.5847, -0.4762, -0.8244,\n",
            "        -0.8494,  0.0500,  0.4977, -0.7930,  0.5240, -0.4543, -0.5152,  0.2508,\n",
            "        -0.8893,  0.2005,  0.2080, -0.1863, -0.0807,  0.4562,  0.5462, -0.7768,\n",
            "         0.5532, -0.7574,  0.3232, -0.0304, -0.3503,  0.8342,  0.2680, -0.0380,\n",
            "         0.6736,  0.0072, -0.6382, -0.4968, -0.8533, -0.2399, -0.6344,  0.1858,\n",
            "         0.3282,  0.0724, -0.2199, -0.6813, -0.5742,  0.5520,  0.1741,  0.0263,\n",
            "         0.5186,  0.1674, -0.4339,  0.4569, -0.4048,  0.0032, -0.0918, -0.0449,\n",
            "         0.4753,  0.5237, -0.4525,  0.7837,  0.2495, -0.0526, -0.4896, -0.9338,\n",
            "         0.1926,  0.6085, -0.2241,  0.4722], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.7988,  0.5205, -0.6961,  0.8550, -0.7997,  0.6265,  0.7382,  0.8523,\n",
            "         0.7688, -0.4728,  0.1401, -0.9562, -0.6847, -0.8827, -0.7847,  0.6548,\n",
            "         0.8784,  0.8648,  0.6433,  0.8900, -0.6731,  0.8536, -0.8089,  0.5799,\n",
            "         0.5081, -0.8572,  0.2793,  0.8042,  0.8824,  0.9233, -0.8293, -0.8772,\n",
            "         0.5372, -0.8117, -0.8532, -0.7941, -0.6522,  0.7196,  0.7974,  0.8868,\n",
            "        -0.5588,  0.2129, -0.7630,  0.7303, -0.9276,  0.8780, -0.5279,  0.0043,\n",
            "        -0.8069, -0.7490,  0.9278, -0.9094,  0.1611,  0.7326, -0.8783,  0.3355,\n",
            "        -0.3140, -0.9414, -0.3591, -0.3171,  0.7611, -0.1803,  0.8322, -0.4383,\n",
            "         0.7761, -0.4592, -0.8393,  0.7579, -0.9381,  0.7371,  0.7557, -0.2435,\n",
            "        -0.9042,  0.8202, -0.8621,  0.3591,  0.8215, -0.5007, -0.7457,  0.9270,\n",
            "         0.9016, -0.8604, -0.5933,  0.7029,  0.6633,  0.1418,  0.6941, -0.8694,\n",
            "        -0.8978,  0.7060,  0.6005,  0.7075,  0.6828, -0.7214, -0.8817,  0.7374,\n",
            "         0.6490, -0.5528, -0.4845, -0.5708], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :a  \n",
            " encoded : tensor([ 0.5615, -0.0105,  0.2461, -0.1568,  0.2541, -0.4443, -0.1092,  0.4132,\n",
            "         0.0174, -0.0108,  0.8903, -0.0734, -0.7384, -0.8390,  0.1000,  0.4512,\n",
            "         0.0921, -0.6816,  0.1878,  0.2885, -0.0736,  0.1950, -0.2555,  0.0242,\n",
            "         0.0357,  0.2883,  0.2395, -0.8340, -0.6568, -0.4116,  0.0124, -0.2348,\n",
            "         0.0013, -0.3695,  0.7883,  0.3418,  0.6550,  0.3729, -0.6486, -0.7863,\n",
            "        -0.7236,  0.3352,  0.4684, -0.0777,  0.0125, -0.3768,  0.5318,  0.2225,\n",
            "         0.6954,  0.8476,  0.6361,  0.2929, -0.6114, -0.4760,  0.3796, -0.5009,\n",
            "         0.7165, -0.1686, -0.4180, -0.3677,  0.1809,  0.8736,  0.4439, -0.5221,\n",
            "         0.1703,  0.4352, -0.5422,  0.3904,  0.0515,  0.4650, -0.8710,  0.4162,\n",
            "         0.4838,  0.6540,  0.4485, -0.2587, -0.2399,  0.2094,  0.5379, -0.1107,\n",
            "         0.4776,  0.1637, -0.4753, -0.0325, -0.2683, -0.3143, -0.5559, -0.0282,\n",
            "         0.3413,  0.2402,  0.5448,  0.6605,  0.5269, -0.1951, -0.0707, -0.5791,\n",
            "        -0.1276, -0.4910, -0.5008, -0.7275], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.8131,  0.5628, -0.7090,  0.8479, -0.8934,  0.8287,  0.8709,  0.8204,\n",
            "         0.8014, -0.5447,  0.4440, -0.9599, -0.7504, -0.9365, -0.7874,  0.8698,\n",
            "         0.8843,  0.9075,  0.8067,  0.9550, -0.7933,  0.9010, -0.8956,  0.6009,\n",
            "         0.5936, -0.8983,  0.3559,  0.9423,  0.9123,  0.9342, -0.8532, -0.8643,\n",
            "         0.7104, -0.8819, -0.9044, -0.8524, -0.7861,  0.7708,  0.8161,  0.9182,\n",
            "        -0.7919,  0.0272, -0.8607,  0.8409, -0.9639,  0.9260, -0.6758, -0.0498,\n",
            "        -0.7506, -0.6469,  0.9539, -0.9388,  0.3428,  0.7452, -0.9039,  0.5584,\n",
            "        -0.4260, -0.9270, -0.5155, -0.3985,  0.7646, -0.5031,  0.9106, -0.7255,\n",
            "         0.8970, -0.6947, -0.9102,  0.8245, -0.9388,  0.8880,  0.7726, -0.1830,\n",
            "        -0.9411,  0.9309, -0.8738,  0.5275,  0.8737, -0.6493, -0.5857,  0.9433,\n",
            "         0.8794, -0.9051, -0.6933,  0.7421,  0.6261,  0.1634,  0.7639, -0.9165,\n",
            "        -0.9288,  0.8275,  0.5657,  0.7134,  0.6282, -0.8680, -0.9294,  0.8686,\n",
            "         0.5962, -0.7025, -0.5368, -0.6857], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :better  \n",
            " encoded : tensor([-0.0312, -0.5555, -0.1932, -0.0653,  0.3624,  0.6645,  0.0683,  0.8405,\n",
            "        -0.0659, -0.4656, -0.0330, -0.5323, -0.4753,  0.4911,  0.0443,  0.2301,\n",
            "         0.4014,  0.1028, -0.0082, -0.5688,  0.1609,  0.4368, -0.7207,  0.1450,\n",
            "        -0.0100,  0.3392,  0.1717,  0.2724, -0.1618, -0.0356,  0.1342,  0.1838,\n",
            "        -0.7477, -0.6201,  0.7353,  0.4811, -0.5538,  0.9024,  0.2214, -0.5668,\n",
            "         0.3330, -0.1316,  0.8115,  0.1202,  0.6305, -0.8338,  0.4087, -0.0525,\n",
            "        -0.8706, -0.3060, -0.1854, -0.3446, -0.6594, -0.0693, -0.5023, -0.6228,\n",
            "         0.6849,  0.1652,  0.2706, -0.4750,  0.1888, -0.1940, -0.8020, -0.8198,\n",
            "         0.5090, -0.3509, -0.5352, -0.2396, -0.9495,  0.3494,  0.1937,  0.2470,\n",
            "        -0.4672,  0.5401,  0.1945, -0.6625,  0.0803, -0.5742,  0.7057,  0.0102,\n",
            "         0.2431, -0.8791, -0.5774,  0.6087,  0.5222, -0.0065, -0.5535, -0.6646,\n",
            "         0.6931, -0.6483,  0.6883,  0.7946, -0.5013, -0.0235, -0.8738, -0.4629,\n",
            "        -0.3042,  0.4585, -0.3508, -0.1910], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.6808,  0.6715, -0.6593,  0.8033, -0.9140,  0.8342,  0.8617,  0.8878,\n",
            "         0.8104, -0.5544,  0.3161, -0.9030, -0.7331, -0.9429, -0.7925,  0.8469,\n",
            "         0.8976,  0.9113,  0.8065,  0.9466, -0.7967,  0.8667, -0.9380,  0.6204,\n",
            "         0.4316, -0.8452,  0.2796,  0.8952,  0.9084,  0.8959, -0.8582, -0.9281,\n",
            "         0.6435, -0.9232, -0.9186, -0.8810, -0.7449,  0.7285,  0.8821,  0.9282,\n",
            "        -0.6477,  0.1027, -0.8041,  0.7272, -0.9409,  0.8916, -0.6858,  0.0643,\n",
            "        -0.7001, -0.4863,  0.9267, -0.9207,  0.3602,  0.7253, -0.9146,  0.5675,\n",
            "        -0.1882, -0.9398, -0.5584, -0.5146,  0.7715, -0.4348,  0.8786, -0.6822,\n",
            "         0.9124, -0.5827, -0.9375,  0.8053, -0.8723,  0.9195,  0.8053, -0.3761,\n",
            "        -0.8826,  0.8903, -0.7508,  0.4857,  0.8519, -0.5141, -0.6402,  0.9511,\n",
            "         0.8605, -0.8422, -0.6898,  0.6420,  0.6146,  0.0450,  0.5911, -0.8911,\n",
            "        -0.7953,  0.8071,  0.7509,  0.7074,  0.7474, -0.9038, -0.8994,  0.7576,\n",
            "         0.6389, -0.6587, -0.5986, -0.6133], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :Obama  \n",
            " encoded : tensor([ 0.1730, -0.3544,  0.2869,  0.1717,  0.5083, -0.6585,  0.3983,  0.2727,\n",
            "        -0.2003, -0.3135, -0.6622,  0.3343,  0.3548, -0.7168, -0.1644,  0.7662,\n",
            "        -0.1341,  0.3071, -0.3196,  0.1434, -0.6614,  0.3481, -0.3311,  0.3527,\n",
            "        -0.5366,  0.5027, -0.8829, -0.0723, -0.8917, -0.6333,  0.8206,  0.0828,\n",
            "        -0.3166,  0.5310,  0.6126, -0.7711,  0.4036,  0.3042, -0.6201, -0.2976,\n",
            "        -0.6414,  0.2029,  0.4010, -0.0913,  0.3069, -0.2890,  0.7466, -0.5552,\n",
            "         0.1406,  0.4819, -0.6067, -0.0015, -0.6178, -0.3331,  0.3590,  0.8227,\n",
            "         0.8635,  0.0498, -0.6820, -0.0763,  0.6869,  0.5751,  0.4496, -0.4895,\n",
            "         0.3660, -0.1122, -0.4559,  0.3663, -0.8887,  0.5332, -0.5991,  0.1537,\n",
            "        -0.0057,  0.5952,  0.6999, -0.4376, -0.6166, -0.2577,  0.1739, -0.2006,\n",
            "         0.4794,  0.0392, -0.7970,  0.0062, -0.2574,  0.5356,  0.4912, -0.3868,\n",
            "         0.1595,  0.1049,  0.5370,  0.5016,  0.4931, -0.6444,  0.4390, -0.7057,\n",
            "        -0.1953,  0.2929, -0.5061, -0.4912], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.8193,  0.5539, -0.6711,  0.8481, -0.7920,  0.8106,  0.8812,  0.8329,\n",
            "         0.7529, -0.4774,  0.4868, -0.9217, -0.7781, -0.9083, -0.7025,  0.8793,\n",
            "         0.8298,  0.9351,  0.8207,  0.9365, -0.7205,  0.9078, -0.9136,  0.7430,\n",
            "         0.5693, -0.8042,  0.4102,  0.9237,  0.8892,  0.9238, -0.8936, -0.9499,\n",
            "         0.6586, -0.8926, -0.8081, -0.9063, -0.7491,  0.7335,  0.8547,  0.8991,\n",
            "        -0.7635,  0.1627, -0.7986,  0.8480, -0.8954,  0.8472, -0.7847,  0.0641,\n",
            "        -0.8536, -0.7518,  0.9362, -0.9486,  0.4196,  0.7266, -0.9109,  0.4425,\n",
            "        -0.3984, -0.9515, -0.5156, -0.5850,  0.8787, -0.3630,  0.8816, -0.5667,\n",
            "         0.9143, -0.6816, -0.9076,  0.8359, -0.8980,  0.9408,  0.8138, -0.4698,\n",
            "        -0.9234,  0.9061, -0.8375,  0.5871,  0.8458, -0.3913, -0.6683,  0.9375,\n",
            "         0.9041, -0.9049, -0.6344,  0.6517,  0.6428,  0.1147,  0.7537, -0.9147,\n",
            "        -0.8809,  0.7962,  0.5210,  0.5876,  0.5442, -0.8603, -0.8870,  0.8182,\n",
            "         0.6728, -0.8293, -0.5951, -0.7256], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :gif  \n",
            " encoded : tensor([-0.3579,  0.6148, -0.4537,  0.1066,  0.5638, -0.5317, -0.4008, -0.6972,\n",
            "         0.4012, -0.4316, -0.5371,  0.0332,  0.7490, -0.1371,  0.3209,  0.6202,\n",
            "        -0.1680,  0.5785, -0.6602, -0.1608,  0.6683,  0.1366, -0.4048,  0.6261,\n",
            "        -0.1817, -0.2332,  0.2493, -0.4804, -0.4738,  0.6764, -0.0392,  0.1353,\n",
            "        -0.5106, -0.4457,  0.1533,  0.0278, -0.1814, -0.3477, -0.3479, -0.8363,\n",
            "         0.4400,  0.2416,  0.1643,  0.3444,  0.1114,  0.4374,  0.0149,  0.1772,\n",
            "        -0.0035,  0.5232, -0.1159,  0.9143, -0.3130,  0.7828,  0.2119, -0.4354,\n",
            "        -0.2879, -0.9162, -0.2887,  0.5826, -0.3041,  0.5286,  0.2019, -0.7610,\n",
            "        -0.0809,  0.4259,  0.4356,  0.7905, -0.7680,  0.6125, -0.3920, -0.6767,\n",
            "         0.3492, -0.6027,  0.1168, -0.5885, -0.1308,  0.5351,  0.5334, -0.3284,\n",
            "        -0.4454, -0.6329, -0.9026, -0.1682,  0.1947, -0.0760, -0.1189, -0.0843,\n",
            "         0.0612, -0.3158,  0.2882,  0.4410, -0.0247,  0.5573, -0.5697, -0.9622,\n",
            "         0.6096,  0.3197, -0.5663,  0.3038], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.7584,  0.7414, -0.7808,  0.7566, -0.7880,  0.7276,  0.7890,  0.7598,\n",
            "         0.8790, -0.5215,  0.3656, -0.8796, -0.7530, -0.8478, -0.8761,  0.7871,\n",
            "         0.8312,  0.7760,  0.7753,  0.8864, -0.7084,  0.8437, -0.7537,  0.6451,\n",
            "         0.6317, -0.8073,  0.5809,  0.7871,  0.8139,  0.8757, -0.9029, -0.9213,\n",
            "         0.6178, -0.8441, -0.8967, -0.8791, -0.7989,  0.4434,  0.8091,  0.9040,\n",
            "        -0.6319, -0.3159, -0.7996,  0.6888, -0.9240,  0.7601, -0.6488, -0.2426,\n",
            "        -0.4146, -0.7558,  0.8490, -0.9104,  0.1286,  0.7431, -0.9023,  0.6067,\n",
            "        -0.2525, -0.9427, -0.6714, -0.3689,  0.7456, -0.5759,  0.7324, -0.6412,\n",
            "         0.8172, -0.7265, -0.8415,  0.8160, -0.8612,  0.8690,  0.8101, -0.4821,\n",
            "        -0.8848,  0.7631, -0.7785,  0.4361,  0.9114, -0.4575, -0.6404,  0.8929,\n",
            "         0.7919, -0.8008, -0.5722,  0.6962,  0.5708,  0.3443,  0.5917, -0.8287,\n",
            "        -0.7959,  0.7513,  0.6941,  0.6851,  0.5579, -0.8818, -0.9349,  0.7691,\n",
            "         0.6653, -0.6464, -0.6484, -0.5031], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :than  \n",
            " encoded : tensor([-0.2776,  0.0860,  0.1483, -0.3726,  0.8971, -0.8223,  0.2314,  0.2250,\n",
            "         0.2337, -0.6437,  0.5298, -0.2392, -0.4625, -0.4960,  0.2131,  0.3141,\n",
            "        -0.2278, -0.2200, -0.6456,  0.2825,  0.5359, -0.2999,  0.6202, -0.2497,\n",
            "        -0.1075,  0.8010,  0.6227, -0.0462, -0.7368, -0.7999,  0.0512, -0.4793,\n",
            "        -0.7335, -0.3346,  0.2426, -0.1178,  0.8159,  0.5663, -0.0833, -0.7553,\n",
            "        -0.5758, -0.3354,  0.6740,  0.6429,  0.2063,  0.8185,  0.6664, -0.1566,\n",
            "        -0.0733,  0.6808, -0.6126,  0.9052, -0.7228,  0.1687,  0.1623, -0.2530,\n",
            "         0.8296, -0.5638, -0.4530, -0.4214, -0.7482,  0.9134,  0.3132,  0.3232,\n",
            "         0.1277, -0.6074, -0.5028,  0.4490, -0.6223,  0.2352, -0.6077, -0.0259,\n",
            "        -0.0750,  0.6442,  0.6015, -0.5368, -0.4895,  0.6108,  0.7965,  0.6654,\n",
            "        -0.0018, -0.4249, -0.4463, -0.1159, -0.3523, -0.5239, -0.1325, -0.8454,\n",
            "         0.5911, -0.3089,  0.3025,  0.6785,  0.5004,  0.1103, -0.7418, -0.6339,\n",
            "         0.2306,  0.2266, -0.3387, -0.3839], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.9066,  0.6900, -0.8686,  0.8758, -0.9328,  0.8146,  0.8612,  0.9102,\n",
            "         0.8127, -0.5284,  0.1098, -0.9412, -0.8056, -0.9474, -0.9287,  0.8390,\n",
            "         0.9066,  0.8827,  0.7108,  0.9312, -0.7496,  0.8605, -0.7996,  0.4429,\n",
            "         0.6887, -0.8515,  0.2965,  0.9231,  0.9081,  0.9624, -0.7369, -0.9249,\n",
            "         0.8464, -0.7970, -0.9165, -0.8983, -0.7918,  0.7632,  0.8283,  0.9280,\n",
            "        -0.4867, -0.3463, -0.8077,  0.5970, -0.9724,  0.8822, -0.5048, -0.3549,\n",
            "        -0.8590, -0.8623,  0.9479, -0.9374,  0.1126,  0.8464, -0.9127,  0.4250,\n",
            "        -0.0269, -0.9407, -0.6830, -0.1142,  0.7537, -0.2759,  0.8139, -0.6946,\n",
            "         0.8190, -0.5901, -0.9267,  0.8739, -0.8758,  0.8920,  0.7490, -0.5499,\n",
            "        -0.9016,  0.8690, -0.8890,  0.3287,  0.8735, -0.7848, -0.7825,  0.9489,\n",
            "         0.8774, -0.8629, -0.2952,  0.8655,  0.7557,  0.5028,  0.7882, -0.9078,\n",
            "        -0.9312,  0.8831,  0.8038,  0.5421,  0.7508, -0.8369, -0.9308,  0.8168,\n",
            "         0.6929, -0.5081, -0.4149, -0.5423], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :this  \n",
            " encoded : tensor([-0.3751,  0.1441,  0.6205,  0.4172,  0.1085, -0.1887,  0.5723,  0.3841,\n",
            "         0.4782, -0.6338,  0.5032, -0.2129,  0.3910, -0.7953, -0.2434,  0.4907,\n",
            "         0.0777, -0.4322, -0.6411, -0.0646,  0.7793,  0.0971, -0.6358,  0.4785,\n",
            "        -0.7966,  0.4434,  0.2911, -0.7597, -0.6203, -0.2020, -0.2839,  0.2195,\n",
            "        -0.1969, -0.6264,  0.3315,  0.1354, -0.1391,  0.5244, -0.5785, -0.8844,\n",
            "        -0.4538,  0.6061,  0.7705,  0.2211,  0.4724, -0.8045, -0.3511, -0.0423,\n",
            "        -0.4742,  0.8007, -0.6827, -0.2875,  0.1152,  0.6989,  0.5554,  0.5425,\n",
            "         0.5033, -0.6863, -0.1386, -0.5732,  0.2060,  0.9506,  0.3755, -0.6683,\n",
            "         0.2708, -0.6414, -0.5873, -0.0776, -0.6558,  0.5551, -0.7946, -0.2175,\n",
            "        -0.1158, -0.1331,  0.6464, -0.7008, -0.1770, -0.0993,  0.7046,  0.2737,\n",
            "         0.6204, -0.2785, -0.8137,  0.0023, -0.3828, -0.2910,  0.6297, -0.2034,\n",
            "         0.5558,  0.4197,  0.6147,  0.8256,  0.1394,  0.1693, -0.4583, -0.7554,\n",
            "         0.4787,  0.1341, -0.6827, -0.6890], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.9217,  0.6418, -0.7978,  0.8829, -0.9029,  0.8254,  0.8673,  0.9409,\n",
            "         0.9025, -0.6683,  0.2840, -0.9589, -0.8440, -0.9704, -0.8700,  0.8829,\n",
            "         0.9231,  0.8961,  0.7640,  0.9670, -0.7632,  0.9393, -0.9421,  0.6667,\n",
            "         0.7000, -0.8801,  0.1663,  0.9281,  0.9551,  0.9713, -0.9082, -0.9299,\n",
            "         0.8408, -0.8857, -0.9177, -0.8694, -0.7553,  0.8246,  0.9086,  0.9585,\n",
            "        -0.6176, -0.1772, -0.8696,  0.7783, -0.9827,  0.9485, -0.6894, -0.0928,\n",
            "        -0.8790, -0.8930,  0.9698, -0.9632,  0.2038,  0.8375, -0.9463,  0.4924,\n",
            "        -0.0333, -0.9692, -0.7425, -0.4270,  0.8383, -0.1171,  0.9163, -0.6806,\n",
            "         0.8866, -0.3177, -0.9344,  0.9070, -0.9539,  0.8986,  0.7861, -0.5607,\n",
            "        -0.9481,  0.9440, -0.9268,  0.2981,  0.8910, -0.6777, -0.8259,  0.9535,\n",
            "         0.9234, -0.9445, -0.6154,  0.8826,  0.7970,  0.3434,  0.7619, -0.9615,\n",
            "        -0.9433,  0.8757,  0.7900,  0.5685,  0.8500, -0.8554, -0.9543,  0.8109,\n",
            "         0.7702, -0.5888, -0.4904, -0.8135], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :one  \n",
            " encoded : tensor([-6.4660e-01,  6.6206e-01,  1.4879e-01,  2.7189e-01,  4.6134e-01,\n",
            "         5.2823e-01,  1.6925e-01,  4.2146e-01,  7.3568e-01, -1.9332e-01,\n",
            "         8.1943e-01, -4.2044e-01,  3.9306e-02, -8.7960e-01,  2.4177e-01,\n",
            "         4.6308e-02, -8.0769e-02, -5.4682e-01, -2.6301e-01, -6.9186e-01,\n",
            "         4.4181e-01,  1.3634e-01, -2.4184e-01,  2.6364e-01, -4.6340e-01,\n",
            "        -2.7156e-04, -3.4953e-01, -7.2330e-01, -7.1186e-01, -4.1912e-01,\n",
            "        -4.3457e-01, -5.5227e-01, -6.1147e-01, -1.4076e-01, -5.0482e-01,\n",
            "         3.2222e-01,  4.2769e-01,  3.8896e-01,  3.9027e-01, -8.4998e-01,\n",
            "        -9.1199e-01, -5.0325e-01,  7.7873e-01, -1.0103e-02,  1.1553e-02,\n",
            "         1.8975e-02, -2.2318e-01, -4.3009e-01, -7.5261e-01,  4.9496e-01,\n",
            "         1.5645e-01,  8.3641e-01,  1.1370e-01, -5.2581e-01,  2.7451e-01,\n",
            "         3.2231e-01,  4.0532e-01, -5.3308e-01, -4.3718e-01, -5.6552e-02,\n",
            "         7.2556e-01,  4.7538e-01, -7.6187e-01,  1.3544e-01,  3.2640e-01,\n",
            "        -1.3706e-01,  1.9986e-01, -4.0251e-01, -6.8832e-01, -1.5996e-01,\n",
            "        -8.3069e-01,  3.9498e-01, -4.4104e-01,  4.5821e-01,  1.5241e-01,\n",
            "         2.1912e-01,  6.0127e-01,  1.5702e-01,  3.9776e-01,  2.2445e-01,\n",
            "         2.0537e-01,  5.7547e-01, -7.3692e-01, -1.6750e-01, -4.3918e-01,\n",
            "         8.7577e-02,  3.6404e-01,  2.9920e-01,  6.7705e-01,  6.4374e-01,\n",
            "        -9.9630e-02,  7.6676e-01,  6.7499e-01,  1.2881e-02, -3.1549e-01,\n",
            "        -1.0809e-01, -1.4575e-01, -5.6692e-02,  3.1400e-01, -9.2651e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.8467,  0.6820, -0.7130,  0.7603, -0.9358,  0.9042,  0.8797,  0.8974,\n",
            "         0.8921, -0.5589,  0.5076, -0.9499, -0.7411, -0.9218, -0.8436,  0.9070,\n",
            "         0.9230,  0.9209,  0.8520,  0.9491, -0.8541,  0.9514, -0.9178,  0.7483,\n",
            "         0.7372, -0.8898,  0.1531,  0.9396,  0.9304,  0.9295, -0.8688, -0.8927,\n",
            "         0.7678, -0.8765, -0.9354, -0.8953, -0.7561,  0.7955,  0.8522,  0.9337,\n",
            "        -0.7943,  0.1275, -0.8787,  0.8271, -0.9423,  0.9158, -0.5417, -0.1345,\n",
            "        -0.7879, -0.8006,  0.9678, -0.9752,  0.4875,  0.7873, -0.9235,  0.6973,\n",
            "        -0.1986, -0.9327, -0.7278, -0.4302,  0.7489, -0.3800,  0.8960, -0.7362,\n",
            "         0.8772, -0.5018, -0.9298,  0.8510, -0.9319,  0.8926,  0.8340, -0.3404,\n",
            "        -0.9475,  0.9658, -0.8450,  0.5013,  0.8199, -0.4705, -0.5884,  0.9514,\n",
            "         0.9484, -0.9418, -0.6935,  0.7707,  0.7382,  0.1461,  0.7393, -0.9381,\n",
            "        -0.9220,  0.8315,  0.5930,  0.7281,  0.7235, -0.8938, -0.9591,  0.8323,\n",
            "         0.5515, -0.6760, -0.5544, -0.7637], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :,  \n",
            " encoded : tensor([-0.6395, -0.1027,  0.3663,  0.0588,  0.3837,  0.5121,  0.6717,  0.5497,\n",
            "         0.6949,  0.0777,  0.4975, -0.8163,  0.4187, -0.5917,  0.2041,  0.3011,\n",
            "         0.2399, -0.3015, -0.6734, -0.1586,  0.3334,  0.2824, -0.1875,  0.2288,\n",
            "        -0.6227, -0.4675, -0.4273, -0.9085, -0.7953, -0.3163, -0.3602, -0.9677,\n",
            "        -0.6202, -0.4589, -0.5764,  0.7415,  0.7402,  0.8073,  0.4989,  0.4313,\n",
            "         0.0119, -0.7175, -0.1195, -0.2583,  0.1457,  0.7112,  0.3247,  0.3689,\n",
            "         0.7065, -0.2368,  0.5881,  0.2528, -0.1969, -0.1564,  0.2368, -0.6577,\n",
            "         0.4604,  0.6173, -0.5834,  0.7643, -0.0968,  0.7402, -0.0222,  0.4019,\n",
            "         0.5912, -0.7244, -0.7556,  0.4496, -0.8177, -0.5414, -0.7528,  0.1866,\n",
            "        -0.4069,  0.6577,  0.2464, -0.1694,  0.1537,  0.3905,  0.7202,  0.2785,\n",
            "         0.6143, -0.6293,  0.8868,  0.2465,  0.6112, -0.8389,  0.3180, -0.3118,\n",
            "         0.3069,  0.7914,  0.0169,  0.0213, -0.0758, -0.4524, -0.6792,  0.7721,\n",
            "        -0.5126, -0.5218,  0.6290, -0.5609], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.6355,  0.6606, -0.5158,  0.7233, -0.9209,  0.8842,  0.8613,  0.8420,\n",
            "         0.9212, -0.3695,  0.4676, -0.8992, -0.6943, -0.7635, -0.6048,  0.8203,\n",
            "         0.8963,  0.8929,  0.8603,  0.9127, -0.8684,  0.9345, -0.9108,  0.7095,\n",
            "         0.5114, -0.8969,  0.4665,  0.9088,  0.8834,  0.8978, -0.8872, -0.8938,\n",
            "         0.4751, -0.8963, -0.9053, -0.8335, -0.7845,  0.6892,  0.8688,  0.9114,\n",
            "        -0.8228,  0.1468, -0.6662,  0.8029, -0.8951,  0.9302, -0.6149,  0.0611,\n",
            "        -0.5477, -0.5890,  0.9329, -0.9558,  0.6531,  0.6886, -0.9003,  0.7119,\n",
            "        -0.4570, -0.9247, -0.4869, -0.5834,  0.7318, -0.2763,  0.8813, -0.7766,\n",
            "         0.8908, -0.5712, -0.8994,  0.7431, -0.9279,  0.9202,  0.8691,  0.1860,\n",
            "        -0.9440,  0.9224, -0.8010,  0.6539,  0.7359, -0.4682, -0.1712,  0.9306,\n",
            "         0.7965, -0.8740, -0.7307,  0.5709,  0.5640, -0.0297,  0.7250, -0.8226,\n",
            "        -0.8463,  0.7099,  0.4118,  0.8119,  0.5592, -0.8713, -0.9365,  0.8595,\n",
            "         0.6058, -0.5800, -0.5797, -0.7403], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :I  \n",
            " encoded : tensor([ 0.0213,  0.1495,  0.3744,  0.4416,  0.5304, -0.4035, -0.1808, -0.2457,\n",
            "         0.4499,  0.4221,  0.7326, -0.2966,  0.2608, -0.7266, -0.2421,  0.6636,\n",
            "         0.4454, -0.3347,  0.2989,  0.0910,  0.6629,  0.3062, -0.6059,  0.6109,\n",
            "        -0.1655, -0.5236, -0.2302, -0.8127, -0.3548, -0.5867, -0.0929, -0.2308,\n",
            "        -0.7370,  0.1667, -0.1528,  0.2776, -0.4521, -0.2309,  0.3134, -0.3934,\n",
            "        -0.5395, -0.1162, -0.2549, -0.8213,  0.0669, -0.3392, -0.7239, -0.5843,\n",
            "         0.8332, -0.4147,  0.0153,  0.2558,  0.3701,  0.7839, -0.2086,  0.1237,\n",
            "        -0.3775, -0.1749, -0.3094, -0.2214,  0.7127,  0.8254, -0.3088,  0.4979,\n",
            "         0.6256,  0.6572, -0.6028, -0.5423, -0.8618, -0.7171, -0.2408,  0.0100,\n",
            "         0.4833, -0.2812,  0.5288,  0.0995, -0.0028,  0.1367,  0.4202, -0.3808,\n",
            "        -0.0043,  0.7520,  0.1836,  0.6068,  0.1114, -0.2027,  0.3185,  0.7970,\n",
            "        -0.4608,  0.8553, -0.7429, -0.3325, -0.3266, -0.8352,  0.4108,  0.9288,\n",
            "        -0.3116,  0.5767,  0.1193, -0.4724], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.4450,  0.6048, -0.1406,  0.4450, -0.6358,  0.7937,  0.8417,  0.6344,\n",
            "         0.8631, -0.2836,  0.6359, -0.8715, -0.4741, -0.4671, -0.1241,  0.8481,\n",
            "         0.7998,  0.8698,  0.9098,  0.8689, -0.8021,  0.8890, -0.9228,  0.8695,\n",
            "         0.3428, -0.8194,  0.4913,  0.8231,  0.7579,  0.5764, -0.9299, -0.7821,\n",
            "        -0.0129, -0.8563, -0.8435, -0.8273, -0.7596,  0.4577,  0.7823,  0.8007,\n",
            "        -0.9131,  0.2972, -0.4727,  0.9072, -0.6563,  0.7928, -0.8298,  0.4770,\n",
            "        -0.4712, -0.1846,  0.8134, -0.9490,  0.6720,  0.4072, -0.8337,  0.7937,\n",
            "        -0.6543, -0.8941, -0.3015, -0.6914,  0.7498, -0.3193,  0.8570, -0.7376,\n",
            "         0.8219, -0.6609, -0.8400,  0.3716, -0.9506,  0.8954,  0.8896,  0.2229,\n",
            "        -0.9199,  0.8235, -0.6489,  0.6495,  0.7879,  0.3621,  0.0755,  0.9102,\n",
            "         0.8138, -0.8414, -0.8555,  0.2509,  0.2102, -0.2626,  0.7426, -0.8193,\n",
            "        -0.7626,  0.4053, -0.0965,  0.7786,  0.1260, -0.8301, -0.9088,  0.7677,\n",
            "         0.4222, -0.7467, -0.6978, -0.7631], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :'m  \n",
            " encoded : tensor([-0.1860,  0.2017, -0.5652,  0.4527, -0.2649, -0.6121,  0.2703,  0.5008,\n",
            "        -0.2614,  0.6688, -0.0795,  0.3179,  0.4062, -0.2084, -0.5653, -0.1589,\n",
            "         0.8367,  0.9635, -0.3625,  0.5917, -0.2374, -0.1031, -0.4693,  0.8081,\n",
            "        -0.4522, -0.4466, -0.3403,  0.1357, -0.7617,  0.0945,  0.0284, -0.8135,\n",
            "        -0.7243, -0.7566,  0.0420, -0.0511,  0.1180,  0.4484,  0.7852, -0.5186,\n",
            "         0.1934, -0.3937, -0.1803, -0.3185, -0.0437,  0.5867,  0.1916, -0.1356,\n",
            "         0.3024,  0.5820,  0.5713,  0.6881,  0.2519, -0.3330,  0.0280,  0.3261,\n",
            "         0.4481,  0.4151, -0.0052,  0.5395, -0.2291,  0.2649, -0.1897,  0.5255,\n",
            "        -0.1302, -0.2219, -0.7723,  0.4832, -0.7179, -0.4381,  0.3190, -0.2646,\n",
            "         0.8072,  0.2741,  0.3816,  0.3458, -0.2503, -0.3356,  0.6144, -0.1867,\n",
            "         0.4252,  0.5075, -0.7278, -0.0532,  0.4067, -0.1149,  0.3527, -0.2746,\n",
            "         0.0277, -0.1018,  0.7661,  0.3798, -0.0518, -0.4856,  0.0039, -0.7622,\n",
            "         0.1627,  0.4635, -0.3618,  0.0630], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.2413,  0.4900, -0.4495,  0.6787, -0.5328,  0.6926,  0.8147,  0.4373,\n",
            "         0.8234, -0.1772,  0.4794, -0.7755, -0.5473, -0.6801, -0.5140,  0.7413,\n",
            "         0.6965,  0.8340,  0.7742,  0.6930, -0.6401,  0.7450, -0.8858,  0.7023,\n",
            "         0.2349, -0.7238,  0.6256,  0.8144,  0.5301,  0.7289, -0.8131, -0.8465,\n",
            "         0.0368, -0.8738, -0.7526, -0.8754, -0.7205,  0.3836,  0.7322,  0.7606,\n",
            "        -0.8979,  0.0689, -0.3541,  0.6516, -0.6580,  0.6764, -0.7875,  0.2973,\n",
            "        -0.1930, -0.1746,  0.7811, -0.8462,  0.4813,  0.4698, -0.8257,  0.5559,\n",
            "        -0.5468, -0.8759, -0.2393, -0.5116,  0.8277, -0.7292,  0.7606, -0.4742,\n",
            "         0.8528, -0.8496, -0.7154,  0.4409, -0.8500,  0.8755,  0.8765,  0.1229,\n",
            "        -0.8159,  0.7634, -0.5905,  0.6782,  0.7828,  0.1440, -0.0176,  0.8876,\n",
            "         0.6772, -0.6251, -0.6891,  0.0868, -0.0241, -0.3080,  0.6101, -0.6250,\n",
            "        -0.4074,  0.3530,  0.0682,  0.8030,  0.0580, -0.7930, -0.8304,  0.7297,\n",
            "         0.5337, -0.7703, -0.7242, -0.4483], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :quitting  \n",
            " encoded : tensor([-0.3650, -0.3370, -0.5589,  0.5741,  0.9126,  0.2160,  0.0522, -0.8672,\n",
            "         0.0638,  0.5654,  0.4813,  0.5532, -0.3788, -0.4487, -0.3257,  0.4013,\n",
            "        -0.2058,  0.2928, -0.0407, -0.4551, -0.5231, -0.4115,  0.3709,  0.2929,\n",
            "        -0.5813, -0.1991, -0.2858, -0.5610,  0.3707, -0.3785,  0.6354, -0.3505,\n",
            "        -0.0780,  0.6833, -0.4159,  0.2679, -0.0629,  0.1114,  0.7491,  0.7934,\n",
            "         0.0963, -0.5316, -0.5958, -0.5580,  0.1720, -0.3932, -0.7003,  0.5526,\n",
            "         0.1637,  0.4461,  0.1712, -0.8300,  0.3230, -0.2999,  0.2413, -0.2741,\n",
            "         0.9128, -0.3319,  0.2026,  0.4500, -0.1916, -0.2029,  0.2429,  0.5476,\n",
            "        -0.0274,  0.1176, -0.0033,  0.6730,  0.1013, -0.2489,  0.1969, -0.2148,\n",
            "        -0.6203, -0.1674,  0.2822, -0.2400, -0.5778, -0.4813, -0.2396, -0.1641,\n",
            "        -0.0228,  0.4837,  0.3024, -0.2409, -0.2526, -0.4166, -0.0592, -0.5247,\n",
            "        -0.6035, -0.1066,  0.0288,  0.4429, -0.0558, -0.0134,  0.2507,  0.2217,\n",
            "        -0.7178, -0.2809, -0.7719,  0.3848], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.2117,  0.5030, -0.4544,  0.4517, -0.5252,  0.5903,  0.7418,  0.2612,\n",
            "         0.7648, -0.1316,  0.5009, -0.4552, -0.5433, -0.2897, -0.3487,  0.6951,\n",
            "         0.6626,  0.7928,  0.7174,  0.6557, -0.6106,  0.6342, -0.6503,  0.6019,\n",
            "         0.3879, -0.7284,  0.6675,  0.6882,  0.3690,  0.2543, -0.8483, -0.7141,\n",
            "        -0.0139, -0.8591, -0.6438, -0.7321, -0.7595,  0.1609,  0.4087,  0.6828,\n",
            "        -0.8389,  0.0244, -0.3221,  0.6395, -0.4658,  0.5775, -0.7391,  0.2425,\n",
            "        -0.0680,  0.0300,  0.6044, -0.7777,  0.4572,  0.3474, -0.6503,  0.4181,\n",
            "        -0.5628, -0.8183, -0.3606, -0.4077,  0.6713, -0.7636,  0.5435, -0.6539,\n",
            "         0.6166, -0.8632, -0.6911,  0.5497, -0.7151,  0.8926,  0.8516,  0.3458,\n",
            "        -0.6855,  0.6309, -0.4647,  0.6551,  0.6323,  0.0216,  0.0137,  0.7812,\n",
            "         0.5514, -0.3841, -0.7071, -0.1644,  0.2793, -0.0149,  0.5605, -0.5413,\n",
            "        -0.4215,  0.3128,  0.2661,  0.7498, -0.0656, -0.6989, -0.8367,  0.7581,\n",
            "         0.0733, -0.7418, -0.7322, -0.0906], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :Twitter  \n",
            " encoded : tensor([-1.4976e-01,  6.3059e-01,  2.7119e-01,  1.4898e-01, -5.3839e-02,\n",
            "         5.1165e-01,  2.0496e-01,  3.6871e-01, -4.5247e-01,  1.6806e-01,\n",
            "        -4.5561e-01, -3.4099e-01,  2.3058e-01,  3.7192e-01, -8.8901e-02,\n",
            "         4.7617e-02, -9.9658e-03,  5.8315e-01,  1.7140e-01, -2.5504e-01,\n",
            "        -4.8640e-01, -3.4227e-01, -3.2216e-01,  3.1660e-02,  6.8679e-01,\n",
            "        -2.7627e-01,  1.7349e-01,  4.5607e-01,  9.4947e-02,  5.3090e-01,\n",
            "        -4.7953e-01,  2.8887e-01,  4.2328e-01,  7.1693e-01,  2.0951e-01,\n",
            "         6.8908e-01, -4.8595e-01, -5.3032e-01,  9.9687e-02,  1.2652e-01,\n",
            "         2.9296e-01,  4.5125e-01, -8.9916e-02, -3.1323e-01, -1.8286e-01,\n",
            "        -6.6192e-02, -3.7358e-01, -4.0616e-01,  1.6297e-04, -4.6830e-01,\n",
            "        -3.2217e-01, -1.8111e-01,  7.4959e-01, -4.8355e-01, -5.1687e-01,\n",
            "         2.2811e-04, -6.0660e-01,  6.7457e-01,  5.0576e-01,  4.5174e-01,\n",
            "        -2.9930e-01, -7.6941e-01, -5.7957e-01, -6.0903e-01, -5.1324e-01,\n",
            "        -7.0636e-02,  5.6178e-01, -3.1564e-01, -1.2376e-01, -5.4010e-01,\n",
            "         3.8040e-01, -3.8783e-01, -4.4812e-02, -4.8528e-01, -3.5107e-02,\n",
            "        -4.1060e-01, -2.9065e-02, -5.4607e-01, -2.9857e-01,  5.5843e-01,\n",
            "         3.7493e-01,  2.7793e-01, -4.5434e-02, -5.6800e-01, -3.0994e-01,\n",
            "        -1.1482e-01, -7.0520e-01,  7.8675e-01,  4.7980e-02,  2.4473e-01,\n",
            "        -2.0243e-01,  5.0747e-01, -3.1614e-01, -2.7108e-01,  5.5330e-01,\n",
            "        -4.2542e-01,  6.8176e-01,  9.4191e-02,  2.9966e-01,  7.7689e-01],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.0475,  0.5224, -0.3247, -0.1490, -0.2682,  0.6385,  0.3927, -0.1337,\n",
            "         0.4690, -0.2682,  0.2488,  0.1161, -0.3629, -0.2369, -0.3121,  0.6276,\n",
            "         0.3846,  0.3050,  0.4888,  0.1441, -0.2071,  0.3712, -0.4878,  0.3879,\n",
            "         0.3665, -0.3172,  0.4643,  0.3673,  0.0203, -0.2429, -0.7879,  0.0516,\n",
            "         0.1248, -0.5320, -0.5903, -0.5549, -0.5836, -0.3882,  0.3373,  0.4617,\n",
            "        -0.6149, -0.1363, -0.1931,  0.4203, -0.1074, -0.2085, -0.3200, -0.1429,\n",
            "         0.1360,  0.2594, -0.0584, -0.5221,  0.3399,  0.1997, -0.5597,  0.5353,\n",
            "        -0.2305, -0.4450, -0.3615, -0.0784, -0.0357, -0.6265,  0.2521, -0.3723,\n",
            "         0.4998, -0.6440, -0.3815,  0.1040, -0.2350,  0.8217,  0.5768, -0.0533,\n",
            "        -0.1501,  0.1489, -0.0447,  0.2981,  0.4639,  0.0840, -0.2350,  0.3638,\n",
            "         0.0593, -0.0744, -0.5572, -0.0130, -0.0082,  0.2878, -0.2303, -0.1584,\n",
            "         0.0917,  0.2132,  0.2981,  0.4953, -0.2615, -0.4608, -0.4118,  0.0346,\n",
            "        -0.2380, -0.2216, -0.5881, -0.0468], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :.  \n",
            " encoded : tensor([ 0.4681,  0.4614, -0.0916, -0.2814,  0.0688, -0.2247, -0.5371, -0.5836,\n",
            "         0.1010, -0.7947, -0.2928,  0.7857, -0.4076,  0.4121,  0.6260, -0.1429,\n",
            "         0.1565, -0.9057,  0.7898, -0.6687, -0.6513, -0.1952,  0.2010, -0.3668,\n",
            "        -0.3938,  0.6476,  0.8119,  0.6377, -0.7026,  0.5627, -0.4139, -0.5896,\n",
            "         0.5616,  0.4623, -0.6103, -0.5010,  0.0513, -0.6081, -0.2255,  0.3829,\n",
            "         0.1785,  0.4066, -0.2551,  0.5012, -0.3412,  0.2897, -0.0773, -0.4324,\n",
            "         0.4117, -0.4872, -0.1922, -0.0734,  0.3741, -0.6829, -0.2148,  0.6054,\n",
            "        -0.4588,  0.5337,  0.2522,  0.3508, -0.2068,  0.1066,  0.6398, -0.4966,\n",
            "        -0.3866,  0.7251,  0.2497,  0.0573,  0.9880,  0.0032,  0.5062, -0.1849,\n",
            "         0.1405,  0.5240, -0.3551,  0.3839,  0.7068, -0.6451, -0.6641,  0.4483,\n",
            "         0.4931,  0.4745,  0.5086, -0.2372,  0.3485,  0.1564, -0.1826, -0.5786,\n",
            "         0.5242, -0.4898,  0.3218,  0.3108,  0.5546,  0.3541,  0.9093, -0.5458,\n",
            "         0.5624,  0.8753,  0.6917,  0.2396], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.2644,  0.5532, -0.3985, -0.4099, -0.3131,  0.5328, -0.2012, -0.3303,\n",
            "        -0.2241, -0.3426, -0.1155,  0.4667, -0.0326,  0.0327, -0.1885,  0.3867,\n",
            "         0.0507, -0.2072,  0.0189, -0.4778,  0.3008, -0.2248,  0.2850, -0.2340,\n",
            "         0.5973,  0.3322, -0.0142, -0.0151, -0.3934, -0.6235, -0.0258,  0.2474,\n",
            "         0.4662,  0.3279,  0.0619, -0.1037, -0.0973, -0.4460, -0.4954, -0.1848,\n",
            "         0.0763, -0.6166, -0.0515, -0.1435,  0.5038, -0.7126,  0.1981, -0.5333,\n",
            "        -0.0831, -0.0186, -0.4578,  0.2394, -0.3217,  0.2692,  0.1594,  0.2657,\n",
            "         0.3816,  0.4898, -0.3881,  0.3754, -0.3790, -0.0897, -0.3759, -0.4588,\n",
            "        -0.2110, -0.4483,  0.1453, -0.0274,  0.5440,  0.1092, -0.0749, -0.1133,\n",
            "         0.2688, -0.3214,  0.0861, -0.2163, -0.2358, -0.4607, -0.2883, -0.2066,\n",
            "        -0.2102,  0.4295,  0.1499,  0.1278,  0.0168,  0.5415, -0.3463,  0.3523,\n",
            "         0.1316,  0.3310,  0.6199, -0.1649,  0.0075,  0.1770,  0.4093, -0.2605,\n",
            "        -0.5103,  0.1470, -0.0051,  0.3036], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "word :http://t.co/cNr0Sr3c  \n",
            " encoded : tensor([ 0.3661, -0.2488, -0.1880, -0.3892,  0.6836,  0.6520, -0.2857, -0.6644,\n",
            "        -0.6109, -0.0893,  0.5352,  0.7036,  0.4893, -0.3228, -0.0290,  0.3194,\n",
            "         0.1135,  0.0784, -0.2640, -0.2075, -0.6495,  0.3546, -0.1947,  0.2606,\n",
            "        -0.9130, -0.7592,  0.4653,  0.6646, -0.7879,  0.7696,  0.2612,  0.0409,\n",
            "        -0.4684,  0.5927,  0.4937,  0.0237, -0.5267, -0.6568, -0.3228,  0.5561,\n",
            "         0.3450, -0.2517,  0.1249,  0.2806,  0.1204,  0.3383, -0.2529,  0.3126,\n",
            "         0.6685, -0.4004, -0.8531, -0.2246, -0.1901,  0.8211, -0.9111, -0.1777,\n",
            "        -0.3921,  0.0523,  0.4468, -0.6940, -0.7215,  0.6590, -0.4636, -0.6011,\n",
            "         0.4889,  0.4157, -0.4289,  0.5365, -0.0578,  0.3436,  0.2117, -0.5020,\n",
            "         0.2394, -0.3350, -0.9494,  0.0388, -0.5747,  0.2445, -0.4517, -0.1545,\n",
            "        -0.7342,  0.4770, -0.8614, -0.4378, -0.2565,  0.2166, -0.4284, -0.4970,\n",
            "        -0.6533, -0.6958,  0.4313,  0.5650,  0.2460,  0.1252,  0.5324,  0.5312,\n",
            "        -0.0020, -0.6005, -0.3928, -0.0856], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([-0.5193,  0.3073, -0.5117, -0.4097,  0.0426, -0.2569, -0.5790, -0.5369,\n",
            "        -0.6933, -0.2368, -0.5685,  0.5300,  0.1213,  0.1155,  0.0920, -0.3733,\n",
            "        -0.3187, -0.4168, -0.3905, -0.5347,  0.6257, -0.2978,  0.5695, -0.5654,\n",
            "         0.4287,  0.5828, -0.4511, -0.5784, -0.1660, -0.6437,  0.3461,  0.4148,\n",
            "         0.2780,  0.6287,  0.3644,  0.5903,  0.1137, -0.1739, -0.5780, -0.2574,\n",
            "         0.6084, -0.5999,  0.1859, -0.4963,  0.4207, -0.5821,  0.4457, -0.5584,\n",
            "         0.2201, -0.2914, -0.2753,  0.4780, -0.6956,  0.1502,  0.3547, -0.4231,\n",
            "         0.4563,  0.4360, -0.2061,  0.6001, -0.6662,  0.1878, -0.5675,  0.1582,\n",
            "        -0.5923,  0.3056,  0.3460, -0.0600,  0.5137, -0.4838, -0.5692, -0.4780,\n",
            "         0.6042, -0.7608, -0.1267, -0.5436, -0.4518, -0.4031, -0.2646, -0.4752,\n",
            "        -0.7279,  0.6411,  0.3851,  0.0456,  0.0523,  0.5317, -0.3814,  0.5580,\n",
            "         0.4729,  0.0762,  0.6739, -0.5527,  0.1545,  0.5016,  0.6400, -0.4162,\n",
            "        -0.4754,  0.6470,  0.3904,  0.5339], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTkHLEipIlM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6cce3c55-74f2-4e9b-abcf-7ac018af2c4b"
      },
      "source": [
        "classify_tweet(tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    }
  ]
}