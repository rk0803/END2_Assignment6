{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "62_LSTMCell.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYiRsFGD6iUC"
      },
      "source": [
        "# Assignment 6\n",
        "Second Architecure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset\n",
        "We will be using previous session tweet dataset. Tweets.csv file is uploaded here. A peek into the dataset is listed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DwDRwcdcOTHf",
        "outputId": "7aaac2bd-61b7-4c57-f303-ba6021e0aa52"
      },
      "source": [
        "upoaded=files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-538eeeff-cc98-4c78-9969-723fa8d4b115\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-538eeeff-cc98-4c78-9969-723fa8d4b115\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving tweets.csv to tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG"
      },
      "source": [
        "df=pd.read_csv('tweets.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2701HIYqZM7V",
        "outputId": "c87fed5f-9bbe-4b68-a450-2efe8bd25050"
      },
      "source": [
        "df.shape\n",
        "df.labels.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields \n",
        "Fields of the dataset are defined as<br/>\n",
        "LABEL as a LabelField<br/>\n",
        "TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case<br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e182bff5-9322-4c0c-90de-d331bc5fa050"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7a0bea6a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6aPdyLBtjEd"
      },
      "source": [
        "Here while defining the Tweet, below, inlcude_lengths is kept True is its needed to loop over the LSTMCells in the decoder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Here we convert list to torchtext. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training\n",
        " and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train_set, valid_set) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572ec062-c0f9-4f3e-a9cf-2d53f1f0401c"
      },
      "source": [
        "(len(train_set), len(valid_set))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset. torchtext can now change this one-hot encoding for us by allowing us to pass a max_size parameter to limit the vocabulary to the most common words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train_set)\n",
        "Label.build_vocab(train_set)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294c6d5c-6072-4792-d3cd-96fe86ce6a61"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train_set, valid_set), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PED4HJWH4t"
      },
      "source": [
        "We use the Embedding, RNN and LSTMCell modules in PyTorch to build a coder, encoder model for classifying tweets.\n",
        "\n",
        "In this model we create three layers. \n",
        "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
        "2. That’s then fed into an RNN layer with 100 hidden features (again, we’re compressing down from the 300-dimensional ).\n",
        "3. Finally, the output of the RNN (the final hidden state after processing the incoming tweet) is pushed through another an LSTMCell. This LSTMCell is then looped over the number of words in a sentence of the tweet. The input to the LSTMCell is single vector from the encoder RNN and its own previous hidden state. Final output, which is  a single vector is then pushed to  standard fully connected layer with three outputs to correspond to our three possible classes (negative, positive, or neutral)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1):\n",
        "      \n",
        "      super().__init__()          \n",
        "      self.hidden_dim=hidden_dim\n",
        "      self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "      # RNN layer for encoding\n",
        "      self.encoder = nn.RNN(embedding_dim,hidden_dim, batch_first=True)\n",
        "      # LSTMCelllayer for decoding\n",
        "      self.decoder=nn.LSTMCell(hidden_dim,hidden_dim)\n",
        "      # Dense layer\n",
        "      self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "      \n",
        "    def forward(self, text, debug = False):\n",
        "      \n",
        "      embedded = self.embedding(text)\n",
        "      #hidden = [batchsize, 1,hidden_dim] as number of layers taken here is 1\n",
        "      output1, hidden = self.encoder(embedded)    \n",
        "      #The output1 of encoder is of shape [batchsize, sent_len, hiddenn_dim], contains hidden states from each time_step \n",
        "      # the input to the decoder LSTMCell is the final single vector from encoder (final hidden state) and its last hidden state and cell state.\n",
        "      \n",
        "      hidden1=hidden.squeeze(dim=0) \n",
        "      output2=[]\n",
        "      for i in range(text.size(1)):\n",
        "        hidden1,cellstate =self.decoder(hidden1)\n",
        "        output2.append(hidden1)\n",
        "      output2=torch.stack(output2, dim=1)\n",
        "      #The output2 of decoder is of shape [batchsize, sent_len, hiddenn_dim], contains hidden states from each time_step \n",
        "\n",
        "      dense_outputs = self.fc(hidden1.squeeze(dim=0))  \n",
        "\n",
        "      # Final activation function softmax\n",
        "      output = F.softmax(dense_outputs, dim=0)       \n",
        "\n",
        "      #Since we want to output at each time step of encoder and decoder, return output1 and output2 as well along with prediction(output)\n",
        "\n",
        "      return output,output1,output2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MsaUDyTQQHN",
        "outputId": "b587189b-9872-4ce4-ec45-7d507a137aa3"
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b276d56-ebfe-476c-928e-fd869c2365b0"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): RNN(300, 100, batch_first=True)\n",
            "  (decoder): LSTMCell(100, 100)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,516,603 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    pred_class = preds.argmax(dim=1)\n",
        "    correct = (pred_class == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe1Fpqcsr4Rx"
      },
      "source": [
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WjEPLKsAiS_"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def model_train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text\n",
        "        tweet,tweet_length = batch.tweets   \n",
        "        \n",
        "        #Capture predictions and output of encode and decoder at every time step.\n",
        "        #Although it is not needed while training it is captured to maintain consistency across.\n",
        "\n",
        "        predictions,o1,o2= model(tweet)\n",
        "        \n",
        "        # compute the loss\n",
        "        #predictions=predictions.squeeze()\n",
        "        loss = criterion(predictions, batch.labels)   \n",
        "\n",
        "        #As the model is overfitting to the training data, regularisation is introduced.     \n",
        "        L2_lambda=0.001\n",
        "        L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())    \n",
        "        loss=loss+L2_lambda*L2_norm    \n",
        "\n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZcHhkkvAsCt"
      },
      "source": [
        "**Evaluation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet,tweet_length  = batch.tweets\n",
        "            \n",
        "            predictions,o1,o2= model(tweet)\n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            L2_lambda=0.001\n",
        "            L2_norm=sum(p.pow(2.0).sum() for p in model.parameters())    \n",
        "            loss=loss+L2_lambda*L2_norm    \n",
        "        \n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4088ec0-9a74-405c-e9bf-cccddff99036"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = model_train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_valid_acc= valid_acc\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')\n",
        "print(f'\\t best Val. Loss: {best_valid_loss:.3f} |  best Val. Acc: {best_valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1389.445 | Train Acc: 66.76%\n",
            "\t Val. Loss: 1381.004 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1373.081 | Train Acc: 68.96%\n",
            "\t Val. Loss: 1364.757 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1356.946 | Train Acc: 68.87%\n",
            "\t Val. Loss: 1348.740 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1341.038 | Train Acc: 68.96%\n",
            "\t Val. Loss: 1332.945 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1325.348 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1317.365 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1309.869 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1301.993 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1294.597 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1286.824 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1279.524 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1271.852 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1264.646 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1257.073 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1249.959 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1242.481 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1235.457 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1228.073 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1221.137 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1213.845 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1206.994 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1199.793 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1193.026 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1185.912 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1179.228 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1172.201 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1165.598 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1158.655 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1152.131 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1145.272 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1138.826 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1132.049 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1125.679 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1118.982 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1112.688 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1106.070 |  Val. Acc: 68.30% \n",
            "\n",
            "\t best Val. Loss: 1106.070 |  best Val. Acc: 68.30% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZgzB0ZkHVTI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqpD5_AHQ73D",
        "outputId": "b39c050c-66ba-4896-c0c7-f2e641316b6a"
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZfnWo0abRx"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]     \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction,o1,o2,h1,h2= model(tensor, debug=True)\n",
        "    #prediction=prediction.squeeze()\n",
        "    pred = torch.argmax(prediction) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr_yA7fF0iP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4362252-bf4e-44e4-b913-600c0bbbac6d"
      },
      "source": [
        "r_n=random.choice(train_set)\n",
        "print(r_n.tweets)\n",
        "tweet=r_n.tweets\n",
        "indexed = [tokenizer[t] for t in tweet]        \n",
        "# compute no. of words        \n",
        "length = [len(indexed)]\n",
        "# convert to tensor                                    \n",
        "tensor = torch.LongTensor(indexed).to(device)   \n",
        "# reshape in form of batch, no. of words           \n",
        "tensor = tensor.unsqueeze(1).T  \n",
        "# convert to tensor                          \n",
        "length_tensor = torch.LongTensor(length)\n",
        "# Get the model prediction                  \n",
        "prediction,o1,o2= model(tensor)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Un', 'genio', 'Obama', 'cantando', '\"', 'Sexy', 'and', 'i', 'know', 'it', '\"', ' ', 'ajajajaj', 'http://t.co/LojgGtGT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8PeU6s91459",
        "outputId": "25a34d8c-742f-4adb-b059-1b0fc03689b0"
      },
      "source": [
        "prediction.size()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z59---5W2Bui",
        "outputId": "289bf307-2f55-41cf-8822-2922d581fe47"
      },
      "source": [
        "o1.size(), o2.size(), len(tweet)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 14, 100]), torch.Size([1, 14, 100]), 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqDEDEbh5Vr2"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_aGbjNr25YR"
      },
      "source": [
        "encoded=o1.squeeze()\n",
        "decoded=o2.squeeze()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agNXjG5e3EcA",
        "outputId": "751a6628-f1b5-498f-f321-92eacbf10efe"
      },
      "source": [
        "encoded.size()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVnHit6w50eP"
      },
      "source": [
        "print(tweet, len(tweet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWp96jA2S38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0148c958-a293-4848-e31d-b566e648f3b1"
      },
      "source": [
        "for i in range(len(tweet)):\n",
        "  enc=encoded[i]\n",
        "  dec=decoded[i]\n",
        "  print(f'word :{tweet[i]}  \\n encoded : {enc}\\n decoded : {dec}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word :Un  \n",
            " encoded : tensor([-0.0277,  0.0705,  0.0005, -0.0142,  0.0917,  0.0717, -0.0249,  0.0175,\n",
            "         0.0275, -0.0535,  0.0009, -0.0220, -0.0510, -0.0680, -0.0249, -0.0631,\n",
            "         0.0658,  0.0241,  0.0179,  0.0109, -0.0296, -0.0184,  0.0163, -0.0529,\n",
            "        -0.0287, -0.0283,  0.0117,  0.0605, -0.0456, -0.0482, -0.0512,  0.0247,\n",
            "        -0.0315,  0.0692,  0.0215,  0.0830, -0.0117,  0.0840,  0.1183,  0.0892,\n",
            "         0.0685, -0.0210,  0.0662, -0.0409,  0.0272,  0.0045,  0.0782, -0.0193,\n",
            "        -0.0679,  0.0072, -0.0060, -0.0379,  0.0168,  0.0847,  0.0242, -0.1152,\n",
            "         0.0194, -0.0058, -0.0663,  0.0081,  0.0554, -0.0812, -0.0618,  0.0098,\n",
            "         0.0099,  0.0813, -0.0271,  0.0057,  0.0753, -0.0386, -0.0329,  0.1023,\n",
            "        -0.0155, -0.0106,  0.0159, -0.0628,  0.0040,  0.0315, -0.0631, -0.0005,\n",
            "         0.0630, -0.0851,  0.0816, -0.0635,  0.0041,  0.0132,  0.0749, -0.0164,\n",
            "         0.0329, -0.0260, -0.0044,  0.0074, -0.0217, -0.0539, -0.0264,  0.0744,\n",
            "         0.0597,  0.0344,  0.0542,  0.0045], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 1.3438e-03, -5.9860e-05, -4.5050e-04,  1.8585e-04,  7.1410e-05,\n",
            "         2.4325e-04, -6.4009e-04, -2.8108e-04, -5.8413e-05, -3.1625e-04,\n",
            "        -8.4841e-05,  3.5225e-03, -2.4924e-03,  1.1050e-03, -1.0174e-04,\n",
            "         3.9453e-04, -1.9494e-04, -2.1205e-03, -4.6719e-04,  1.4735e-03,\n",
            "        -1.1932e-04, -2.1478e-04, -1.2054e-03, -3.6488e-04,  8.9471e-05,\n",
            "         1.8368e-03, -6.2581e-04, -2.5901e-03,  2.4007e-03,  9.0190e-04,\n",
            "         8.9149e-04, -1.6398e-04,  2.3834e-04,  9.5733e-05, -1.5180e-03,\n",
            "         9.4415e-05, -5.1284e-04,  4.9798e-04,  5.3556e-04, -3.7273e-04,\n",
            "         2.5217e-04,  2.3835e-04,  1.6033e-03,  2.2207e-04, -1.3414e-04,\n",
            "         6.4911e-04,  3.9547e-05,  2.9901e-03,  4.7507e-04,  9.6638e-04,\n",
            "        -8.9023e-04, -2.1361e-03,  5.4769e-04, -8.9626e-04,  4.9712e-04,\n",
            "         5.8408e-04,  2.2674e-05, -4.4906e-04,  3.8048e-04,  8.5033e-04,\n",
            "         8.1164e-04, -2.6284e-03,  6.1054e-05, -1.2860e-04, -8.2923e-05,\n",
            "        -1.1022e-03, -1.3325e-04,  2.6489e-04, -6.4715e-04, -1.0853e-03,\n",
            "         2.1106e-03, -8.2598e-04,  2.3617e-03, -9.7398e-04,  1.8698e-04,\n",
            "        -1.0948e-03,  5.7300e-04, -6.9825e-04, -4.8915e-04, -9.4899e-04,\n",
            "        -1.6797e-04,  6.2226e-04,  1.0441e-04,  1.0558e-04, -4.4045e-04,\n",
            "         1.3376e-03,  3.3228e-04, -5.6329e-04,  9.5298e-04, -1.8487e-03,\n",
            "        -3.9942e-04, -3.3113e-04, -6.3885e-04,  6.6974e-04, -3.6049e-04,\n",
            "         3.8731e-04,  5.8433e-04, -1.9700e-04,  3.9815e-03,  2.9074e-04],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :genio  \n",
            " encoded : tensor([-0.0529, -0.0115, -0.0081,  0.0263, -0.0449, -0.0335,  0.0057,  0.0198,\n",
            "         0.0244, -0.0400,  0.0209,  0.0144,  0.0390,  0.0861, -0.0264, -0.0338,\n",
            "         0.1220,  0.0446, -0.0108, -0.0868,  0.0907, -0.0936,  0.0429, -0.0085,\n",
            "        -0.0058,  0.0331, -0.0140, -0.0078, -0.0108,  0.0231,  0.0456,  0.0232,\n",
            "         0.0385,  0.0120,  0.0353, -0.0237,  0.0487,  0.0742, -0.0275,  0.0532,\n",
            "        -0.0592,  0.0694,  0.0179, -0.0284,  0.0536,  0.0308,  0.0264, -0.0108,\n",
            "         0.0512, -0.0259, -0.0027, -0.0103,  0.0250, -0.0196,  0.0026,  0.0019,\n",
            "         0.0574,  0.0074, -0.0674,  0.0200,  0.0615, -0.0771,  0.0428, -0.0417,\n",
            "         0.0373,  0.0269, -0.0271,  0.0130, -0.0194,  0.0469, -0.0021,  0.0478,\n",
            "         0.0679, -0.0645, -0.0859, -0.0243,  0.0555, -0.0649, -0.0260, -0.0485,\n",
            "         0.0613, -0.0437,  0.0364,  0.0124, -0.0406,  0.0130,  0.0045, -0.0816,\n",
            "        -0.0171, -0.0267,  0.0638,  0.0343, -0.0715,  0.0256, -0.0654, -0.0351,\n",
            "        -0.0759,  0.0167,  0.0778, -0.0042], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6106e-04, -2.1237e-04, -8.9228e-04, -2.6792e-06,  6.8314e-07,\n",
            "        -5.3290e-06,  5.0906e-05, -9.3878e-05, -4.9401e-06, -6.8911e-05,\n",
            "        -1.7426e-05,  3.1752e-03, -2.3708e-03,  2.8329e-04, -4.2157e-06,\n",
            "        -2.9047e-06, -1.0300e-04, -2.1387e-03,  5.0304e-06,  1.6707e-03,\n",
            "        -3.5304e-04,  5.1091e-05, -7.5492e-04, -7.9322e-06,  9.0455e-07,\n",
            "         2.4663e-03, -1.0681e-04, -2.3985e-03,  2.4660e-03,  7.8367e-04,\n",
            "         1.1598e-03, -1.3572e-05, -4.6165e-06, -1.5626e-05, -1.3476e-03,\n",
            "         2.0704e-04, -5.5502e-07, -2.8679e-06,  9.1686e-05,  4.8534e-05,\n",
            "        -1.8436e-04, -1.6409e-05,  1.6461e-03,  5.5273e-06,  9.1002e-05,\n",
            "         3.9261e-04, -9.8650e-06,  2.4161e-03, -1.0427e-05,  3.5345e-04,\n",
            "        -1.3785e-03, -1.4681e-03,  1.0050e-05,  2.8004e-04,  1.2384e-04,\n",
            "        -2.4668e-04,  7.4966e-05, -7.1520e-04,  3.3537e-04,  3.9341e-04,\n",
            "         3.2222e-04, -1.7859e-03,  1.5761e-06, -2.0277e-04,  1.2352e-04,\n",
            "        -4.6384e-04, -6.2521e-06,  2.3618e-04, -2.3860e-06, -4.7562e-04,\n",
            "         1.1616e-03, -5.8086e-04,  2.3758e-03, -1.8230e-03, -1.2431e-04,\n",
            "        -7.7239e-04,  8.1094e-04,  3.0654e-05,  6.9250e-06, -6.2231e-04,\n",
            "         1.4601e-05,  7.9366e-04,  1.0936e-04, -1.1707e-04, -4.7690e-04,\n",
            "         8.8242e-04, -1.5314e-05,  4.1225e-05,  1.3294e-03, -2.1050e-03,\n",
            "         2.5750e-06, -3.5830e-05, -1.0802e-03,  7.6627e-04, -2.5784e-06,\n",
            "        -3.4582e-05,  8.8641e-06, -1.3276e-04,  3.3725e-03, -1.1861e-05],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :Obama  \n",
            " encoded : tensor([ 0.0929, -0.0275,  0.0141, -0.0256, -0.1178, -0.0603,  0.0593,  0.0075,\n",
            "        -0.0093,  0.0102, -0.0251,  0.0185, -0.0081, -0.0256, -0.0283,  0.0183,\n",
            "         0.0626, -0.0175, -0.0265, -0.0137,  0.0478, -0.0741,  0.0756, -0.0236,\n",
            "        -0.0140,  0.0164, -0.0170,  0.0373, -0.0491,  0.0345, -0.0207,  0.0334,\n",
            "        -0.0247, -0.0043, -0.0282, -0.0556, -0.0398,  0.0430,  0.0932,  0.0148,\n",
            "        -0.0819, -0.0428, -0.0188, -0.0338, -0.0127, -0.0101,  0.0143, -0.0284,\n",
            "         0.0496, -0.0251, -0.0892,  0.0057,  0.0608, -0.0254,  0.0375,  0.0310,\n",
            "        -0.0298, -0.0044, -0.0234,  0.0931, -0.0671,  0.0963,  0.0057, -0.0834,\n",
            "         0.0051, -0.0077,  0.0173, -0.0348, -0.0451,  0.0368,  0.0411,  0.0637,\n",
            "         0.0269, -0.0585, -0.0332,  0.0126,  0.0167, -0.0605, -0.0616,  0.0279,\n",
            "        -0.0138,  0.0337, -0.0074, -0.0407, -0.0180,  0.0500, -0.0653, -0.0049,\n",
            "         0.0368, -0.0181,  0.0510,  0.0671,  0.0362, -0.0197,  0.0012,  0.1164,\n",
            "        -0.0059,  0.0203, -0.0742,  0.0329], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6489e-04, -2.1912e-04, -8.8961e-04, -3.7058e-06,  4.4820e-06,\n",
            "        -3.0382e-06,  4.6612e-05, -8.5792e-05, -5.7875e-06, -6.5238e-05,\n",
            "        -1.3559e-05,  3.1754e-03, -2.3696e-03,  2.8056e-04, -1.2664e-06,\n",
            "        -1.5187e-06, -1.0439e-04, -2.1384e-03,  3.7313e-06,  1.6641e-03,\n",
            "        -3.5739e-04,  4.8112e-05, -7.5195e-04, -6.8927e-06, -1.5795e-06,\n",
            "         2.4659e-03, -1.0211e-04, -2.3958e-03,  2.4646e-03,  7.8307e-04,\n",
            "         1.1597e-03, -1.1608e-05, -8.1733e-06, -1.0743e-05, -1.3508e-03,\n",
            "         2.0234e-04,  5.8164e-06, -2.9809e-06,  9.2235e-05,  4.1463e-05,\n",
            "        -1.8478e-04, -1.1083e-05,  1.6411e-03,  1.3859e-06,  8.5652e-05,\n",
            "         3.8949e-04, -8.1476e-06,  2.4176e-03, -7.8954e-06,  3.5157e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0665e-05,  2.7979e-04,  1.2683e-04,\n",
            "        -2.5090e-04,  7.2963e-05, -7.1575e-04,  3.3184e-04,  3.9484e-04,\n",
            "         3.2770e-04, -1.7875e-03,  3.1692e-06, -2.0148e-04,  1.2025e-04,\n",
            "        -4.6344e-04, -2.7064e-06,  2.3783e-04, -1.7895e-06, -4.7632e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8213e-03, -1.2378e-04,\n",
            "        -7.7729e-04,  8.0659e-04,  2.7217e-05,  7.3995e-06, -6.1631e-04,\n",
            "         1.6759e-05,  7.9139e-04,  1.1282e-04, -1.1655e-04, -4.7216e-04,\n",
            "         8.8785e-04, -1.8925e-05,  3.5222e-05,  1.3252e-03, -2.1077e-03,\n",
            "        -8.0314e-08, -4.2401e-05, -1.0852e-03,  7.6807e-04, -2.4274e-06,\n",
            "        -3.2906e-05,  6.6855e-06, -1.2762e-04,  3.3668e-03, -9.1836e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :cantando  \n",
            " encoded : tensor([ 0.0574,  0.0152,  0.0194, -0.0126,  0.0961, -0.0029, -0.0162, -0.0728,\n",
            "        -0.0163, -0.0202,  0.0053, -0.0405,  0.0404,  0.0097,  0.0424,  0.0240,\n",
            "        -0.0292, -0.0296,  0.0049,  0.0486, -0.0501, -0.0224, -0.0409, -0.0407,\n",
            "        -0.0310,  0.0041, -0.0015,  0.0359,  0.0294,  0.0310,  0.0681, -0.0249,\n",
            "        -0.0164,  0.0230,  0.0057, -0.0536, -0.0162,  0.0247,  0.0298,  0.1368,\n",
            "         0.0542,  0.0360,  0.0898, -0.0038,  0.0795, -0.0069,  0.0624,  0.0450,\n",
            "         0.0189, -0.0020,  0.0177, -0.0289, -0.0175, -0.0220,  0.0075,  0.0371,\n",
            "         0.0207, -0.0299,  0.0147, -0.0431, -0.0300,  0.0830,  0.0472, -0.0062,\n",
            "         0.0444, -0.0076,  0.0256, -0.0243,  0.0838,  0.0266,  0.0589, -0.0337,\n",
            "         0.1254, -0.0348, -0.0128, -0.0326, -0.0042,  0.0658,  0.0758, -0.0248,\n",
            "        -0.0263,  0.0007, -0.0537,  0.0478,  0.0029, -0.0326, -0.0332,  0.0604,\n",
            "        -0.0509, -0.0012,  0.1008,  0.0512,  0.0396, -0.0462, -0.0143, -0.0593,\n",
            "         0.0702,  0.0379, -0.0382, -0.0603], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4728e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7903e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2825e-06,\n",
            "        -1.4840e-06, -1.0443e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9296e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1842e-06, -1.0767e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8146e-06, -3.0014e-06,  9.2249e-05,  4.1476e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3416e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1175e-06,  2.4176e-03, -7.9145e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1397e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6519e-06,  2.3782e-04, -1.8025e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3977e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5255e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4631e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3949e-06,\n",
            "        -3.2892e-05,  6.6519e-06, -1.2761e-04,  3.3668e-03, -9.2220e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :\"  \n",
            " encoded : tensor([ 0.0042, -0.0216, -0.0576, -0.0140, -0.0091, -0.1063, -0.0224,  0.0279,\n",
            "        -0.0656, -0.0673,  0.0772,  0.0583,  0.0291, -0.0215,  0.0726, -0.0065,\n",
            "         0.0149, -0.0498, -0.0469, -0.0137,  0.0955,  0.0174, -0.0251,  0.0545,\n",
            "         0.0033,  0.0426,  0.0787, -0.0333,  0.0621,  0.1081, -0.0405,  0.0025,\n",
            "        -0.0849,  0.0373,  0.0372, -0.0130,  0.0264,  0.0164, -0.0057,  0.0402,\n",
            "        -0.0478,  0.0442,  0.0286,  0.0316,  0.1070, -0.0441,  0.0428,  0.0778,\n",
            "         0.0275,  0.0175,  0.0039, -0.0565,  0.0136,  0.0124, -0.0192, -0.0009,\n",
            "         0.0008,  0.0323,  0.0063,  0.0302,  0.0420,  0.0206,  0.0159,  0.0123,\n",
            "         0.0414,  0.0175, -0.0041, -0.0381, -0.0484,  0.0031,  0.0623,  0.0992,\n",
            "         0.0351,  0.0671,  0.0554, -0.0461, -0.0879,  0.0086,  0.0801, -0.0049,\n",
            "        -0.1180, -0.0238, -0.0261, -0.0289,  0.0175,  0.0064, -0.0282,  0.0297,\n",
            "         0.0551, -0.0410,  0.0182, -0.0183,  0.0588,  0.0531, -0.0035,  0.0500,\n",
            "        -0.0493, -0.0111,  0.0131, -0.0614], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :Sexy  \n",
            " encoded : tensor([-0.0738,  0.0500,  0.1042,  0.0338, -0.0285,  0.0324,  0.0474, -0.0342,\n",
            "         0.0832,  0.0061,  0.0800, -0.0638,  0.0133, -0.0170, -0.0354,  0.0014,\n",
            "        -0.0790, -0.0265, -0.0555, -0.0185,  0.0352, -0.0038,  0.0121, -0.0212,\n",
            "        -0.0955, -0.0676,  0.0406, -0.0432, -0.0952, -0.0049,  0.0265, -0.0616,\n",
            "         0.0293, -0.0110,  0.0023,  0.0816, -0.0063,  0.1147, -0.0204,  0.0321,\n",
            "        -0.0191, -0.0439, -0.0803, -0.0014, -0.0046, -0.0241, -0.0143,  0.0877,\n",
            "        -0.0291,  0.0109,  0.0254, -0.0723,  0.0221,  0.0384,  0.0207, -0.0832,\n",
            "         0.0708, -0.0154,  0.0460,  0.0335, -0.0061,  0.0490, -0.0493, -0.0040,\n",
            "        -0.0200,  0.0179,  0.0143, -0.0102,  0.0666, -0.0790,  0.0244, -0.0123,\n",
            "        -0.0044, -0.0715, -0.0166, -0.0744, -0.0286, -0.0110,  0.0156, -0.0116,\n",
            "         0.0294,  0.0675,  0.0996, -0.0467, -0.0051, -0.0350, -0.1842, -0.0043,\n",
            "        -0.0172, -0.0014,  0.0206, -0.0304, -0.0296,  0.0607,  0.0166,  0.0248,\n",
            "         0.0065, -0.0121,  0.0295, -0.0391], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :and  \n",
            " encoded : tensor([ 3.7717e-02,  2.3138e-02,  6.3241e-03, -1.6326e-02,  6.1675e-02,\n",
            "         2.1082e-02, -1.0440e-02,  5.7546e-02,  1.9728e-02, -2.4224e-02,\n",
            "         8.5851e-02,  1.0148e-02,  2.3561e-02, -9.2598e-02, -9.5928e-02,\n",
            "        -1.1207e-02, -8.3440e-02,  1.3709e-02,  3.2948e-02, -4.6163e-02,\n",
            "        -8.5280e-02,  7.4503e-02,  6.1446e-03, -5.1700e-02, -6.3012e-02,\n",
            "        -8.1906e-03, -2.2988e-02,  8.1592e-02,  4.2349e-03, -8.6549e-02,\n",
            "        -5.6699e-02, -1.9579e-02, -3.4808e-02,  1.3041e-03,  6.0402e-02,\n",
            "        -8.0806e-03,  3.9040e-02,  7.0813e-02, -8.0056e-02, -7.0299e-02,\n",
            "         1.5713e-02, -5.9652e-02, -1.2056e-01,  1.4412e-02,  3.3510e-02,\n",
            "         1.2058e-02,  4.8996e-02,  9.1942e-03, -2.1151e-02,  4.9969e-02,\n",
            "         1.2991e-04, -3.6009e-02,  4.0330e-03,  2.9792e-02,  1.1000e-02,\n",
            "        -3.7250e-02, -3.7604e-02, -3.6827e-02, -7.0892e-02, -7.5774e-02,\n",
            "        -5.2754e-02, -2.6301e-02, -3.4341e-02, -7.0998e-03, -3.0771e-02,\n",
            "        -5.7412e-02, -1.2611e-01,  6.6410e-03,  1.1431e-02, -6.3379e-02,\n",
            "        -3.6344e-02,  2.1152e-02,  6.5790e-02, -2.0281e-03,  1.4819e-04,\n",
            "         6.1069e-03,  7.4100e-02,  1.9776e-02, -8.5275e-03, -4.1720e-02,\n",
            "         3.1674e-02,  7.1902e-03,  4.5834e-03, -2.2707e-02,  5.3981e-02,\n",
            "        -3.1602e-02,  3.0287e-02,  1.2208e-02,  1.2532e-02,  3.2061e-02,\n",
            "         7.7258e-02, -1.4007e-02, -3.3358e-03, -6.9230e-02, -2.8216e-03,\n",
            "        -1.5570e-02,  3.0977e-02, -5.1537e-03, -2.7887e-05,  6.7908e-03],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :i  \n",
            " encoded : tensor([ 2.1371e-02, -6.3017e-02,  2.9931e-02, -1.4352e-02,  3.2505e-02,\n",
            "        -6.9385e-04, -2.6799e-02, -2.5055e-02,  2.7861e-02,  4.2011e-02,\n",
            "        -1.8362e-02,  4.2140e-02,  2.5242e-02, -4.9145e-02, -2.9353e-02,\n",
            "        -1.6557e-02, -5.3376e-02,  6.0224e-05,  1.1425e-02,  8.2246e-03,\n",
            "         5.4048e-02,  8.8832e-02,  2.7524e-02, -3.6930e-02, -1.2262e-02,\n",
            "         3.9619e-03,  1.5375e-02, -7.6082e-02,  1.0753e-01, -7.6304e-03,\n",
            "        -2.4828e-03,  1.5241e-02, -2.9235e-02, -5.1017e-02, -3.1118e-02,\n",
            "        -9.1642e-02,  1.7199e-02,  6.3398e-02,  1.4919e-02, -1.0577e-02,\n",
            "         1.6908e-02, -1.0608e-02,  7.2906e-02, -2.1385e-03,  1.6079e-02,\n",
            "        -9.2208e-02,  1.0749e-01,  1.9179e-02,  3.1189e-02,  1.5378e-02,\n",
            "         4.1117e-02, -2.9687e-02,  4.4662e-02,  1.2583e-01, -2.1935e-02,\n",
            "         6.3768e-02, -8.1044e-02, -1.7933e-02, -4.4545e-02, -1.5990e-02,\n",
            "         6.0021e-03,  4.1265e-02, -2.6440e-02,  5.9004e-02,  5.0672e-02,\n",
            "         7.5135e-02,  6.5798e-04, -5.0409e-02,  2.5878e-02,  1.7170e-02,\n",
            "         1.9295e-02,  4.4656e-03, -1.0304e-03,  1.5568e-02, -7.0110e-03,\n",
            "         1.6147e-02, -7.3997e-02,  6.9035e-03,  1.1930e-01, -6.8762e-02,\n",
            "        -1.7507e-02, -1.0208e-02,  4.0826e-02,  6.0914e-02, -6.9513e-02,\n",
            "         1.2226e-02,  7.1521e-02, -4.8429e-02,  1.2540e-01, -2.8057e-02,\n",
            "        -1.8270e-02,  5.0122e-02,  5.3356e-02, -3.2403e-02,  2.1493e-02,\n",
            "        -6.3195e-02, -2.1540e-02,  4.4369e-02,  7.7523e-02, -2.9037e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :know  \n",
            " encoded : tensor([ 9.8957e-02, -2.6206e-02, -4.6025e-02, -6.4279e-02,  1.3568e-01,\n",
            "         1.0310e-02, -3.5540e-02,  4.8207e-02,  3.8775e-02,  1.4084e-03,\n",
            "        -1.5111e-06,  1.9130e-02,  7.7650e-02,  1.9800e-02, -6.9244e-03,\n",
            "         1.7299e-02,  2.0607e-02,  1.5476e-02,  3.0475e-02,  4.5597e-02,\n",
            "         2.1828e-03, -3.4868e-02, -8.7324e-02, -5.5067e-02, -6.0739e-02,\n",
            "         8.8796e-03, -3.1259e-02,  3.5011e-02, -6.1028e-03, -3.2768e-02,\n",
            "        -4.6565e-02, -3.6382e-02, -1.5403e-02, -8.7095e-03,  3.4591e-02,\n",
            "         8.0832e-02, -6.1353e-02, -4.8906e-02,  6.3519e-03,  6.0280e-02,\n",
            "         1.9541e-02,  4.2886e-02, -3.5622e-02, -1.5693e-03, -5.3824e-03,\n",
            "        -1.8806e-02, -1.2273e-02,  1.3074e-02, -9.9077e-03,  6.0646e-02,\n",
            "         1.0906e-02, -4.5339e-02, -2.4849e-02, -4.9117e-02,  2.7907e-02,\n",
            "         2.3700e-02, -2.0325e-02, -6.1718e-02, -2.7139e-02, -1.9913e-02,\n",
            "         5.5850e-02, -5.5815e-02, -2.6509e-03,  3.7544e-02, -1.0360e-02,\n",
            "        -1.3976e-02, -6.8702e-02,  3.3854e-02, -5.0515e-02, -4.4150e-02,\n",
            "        -3.5493e-02,  1.1579e-01, -6.8593e-02, -2.6370e-03,  3.3855e-02,\n",
            "         5.4010e-02, -4.1236e-02, -6.7118e-02,  1.0776e-02, -3.3387e-02,\n",
            "        -5.1402e-02, -4.2089e-02,  3.8524e-02,  9.1059e-02,  3.3039e-02,\n",
            "         2.5459e-02,  2.4047e-02, -1.2843e-02, -9.2117e-03,  3.0212e-02,\n",
            "         3.7361e-02,  2.5796e-02, -3.2522e-02,  2.6310e-02, -3.5244e-02,\n",
            "        -4.9244e-02,  1.5733e-02, -5.4477e-02,  5.4513e-02, -7.5038e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :it  \n",
            " encoded : tensor([ 0.0436,  0.0919,  0.0725,  0.0392,  0.0194,  0.0065, -0.0527, -0.0154,\n",
            "         0.0350,  0.0105,  0.0539,  0.0115,  0.1184,  0.1001, -0.0054,  0.0510,\n",
            "         0.0786,  0.0709,  0.0559, -0.0046,  0.0060, -0.0152,  0.0218, -0.0298,\n",
            "         0.0293,  0.0095, -0.0073,  0.0247, -0.0079,  0.0638,  0.0012, -0.0774,\n",
            "        -0.0505,  0.0557, -0.0735,  0.0952,  0.0722, -0.0486, -0.0101,  0.0025,\n",
            "         0.0463, -0.0359,  0.0556, -0.0505,  0.0376, -0.0737, -0.0359,  0.0505,\n",
            "         0.0595,  0.0071, -0.0874,  0.0384,  0.0653, -0.0045, -0.0070, -0.0351,\n",
            "        -0.0321, -0.0603,  0.0178,  0.0067, -0.0197,  0.0571,  0.0007,  0.0463,\n",
            "         0.0262,  0.0116,  0.0448, -0.0033,  0.0479, -0.0211,  0.0035, -0.0302,\n",
            "         0.0150, -0.0160,  0.0361, -0.0568, -0.1188,  0.0305,  0.0889,  0.0957,\n",
            "         0.0490,  0.0087,  0.0321, -0.0347,  0.0463,  0.0150,  0.0115, -0.0028,\n",
            "         0.0562, -0.0416, -0.0451,  0.0156, -0.0182, -0.0962,  0.0128, -0.0371,\n",
            "        -0.0042,  0.0510, -0.0242,  0.0438], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :\"  \n",
            " encoded : tensor([ 0.0039, -0.0233, -0.0599, -0.0158, -0.0080, -0.1071, -0.0185,  0.0240,\n",
            "        -0.0660, -0.0676,  0.0781,  0.0547,  0.0285, -0.0210,  0.0726, -0.0088,\n",
            "         0.0135, -0.0509, -0.0466, -0.0171,  0.0975,  0.0170, -0.0272,  0.0537,\n",
            "         0.0033,  0.0421,  0.0740, -0.0344,  0.0579,  0.1115, -0.0417,  0.0020,\n",
            "        -0.0863,  0.0375,  0.0380, -0.0136,  0.0258,  0.0149, -0.0050,  0.0383,\n",
            "        -0.0480,  0.0456,  0.0286,  0.0324,  0.1072, -0.0432,  0.0451,  0.0733,\n",
            "         0.0294,  0.0158,  0.0020, -0.0555,  0.0127,  0.0166, -0.0188, -0.0023,\n",
            "        -0.0013,  0.0322,  0.0061,  0.0315,  0.0410,  0.0196,  0.0168,  0.0111,\n",
            "         0.0411,  0.0204, -0.0046, -0.0368, -0.0505,  0.0030,  0.0599,  0.0975,\n",
            "         0.0329,  0.0679,  0.0560, -0.0456, -0.0892,  0.0081,  0.0824, -0.0031,\n",
            "        -0.1174, -0.0254, -0.0263, -0.0314,  0.0200,  0.0074, -0.0276,  0.0282,\n",
            "         0.0549, -0.0391,  0.0163, -0.0202,  0.0600,  0.0537, -0.0028,  0.0498,\n",
            "        -0.0493, -0.0112,  0.0096, -0.0605], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :   \n",
            " encoded : tensor([-0.0406,  0.0449,  0.0876, -0.0275,  0.0461,  0.0008,  0.0350,  0.1000,\n",
            "         0.0448, -0.0533, -0.0310,  0.0359,  0.0374,  0.0390,  0.0314, -0.0609,\n",
            "         0.0530,  0.0780,  0.0112, -0.0738, -0.0028,  0.0066,  0.0374,  0.0458,\n",
            "        -0.0902,  0.0171, -0.0038,  0.0190,  0.0250,  0.0085,  0.0069,  0.0023,\n",
            "         0.0187, -0.0474,  0.0235, -0.0057,  0.0173, -0.0109, -0.0824,  0.1286,\n",
            "        -0.0287, -0.0356,  0.0329,  0.0174, -0.0733, -0.0153, -0.0193,  0.0164,\n",
            "         0.0467,  0.0062,  0.0170, -0.0848,  0.0101, -0.0681, -0.0561, -0.0351,\n",
            "        -0.0179,  0.0045,  0.0529,  0.0151,  0.0324, -0.0158,  0.0179,  0.0358,\n",
            "         0.0565,  0.0450,  0.0294, -0.0011, -0.0798, -0.0541, -0.0500, -0.0016,\n",
            "        -0.0066,  0.0147, -0.0503,  0.0585,  0.0540, -0.0966, -0.0085,  0.0057,\n",
            "        -0.0533,  0.0494, -0.0897, -0.0385,  0.0840,  0.0695, -0.0086,  0.0353,\n",
            "        -0.0383, -0.0688, -0.0753, -0.0400, -0.0232,  0.0160,  0.0168,  0.0424,\n",
            "         0.0259,  0.0468, -0.0814,  0.0398], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :ajajajaj  \n",
            " encoded : tensor([-0.0139,  0.0402,  0.0287,  0.0138,  0.0219,  0.0868, -0.0105,  0.0487,\n",
            "         0.0496,  0.0438,  0.0882, -0.0514, -0.1510, -0.0664,  0.0235,  0.0523,\n",
            "         0.0647, -0.0095, -0.1083,  0.0494, -0.1090, -0.0420, -0.0044,  0.0056,\n",
            "         0.0519,  0.0422,  0.0834,  0.0096,  0.0505,  0.0835,  0.0446,  0.0373,\n",
            "        -0.0617, -0.0394,  0.0071, -0.0161, -0.0621, -0.0582,  0.0558, -0.0189,\n",
            "         0.0838, -0.0605, -0.0113,  0.0422, -0.1132, -0.1289, -0.0392, -0.0324,\n",
            "         0.0612, -0.0604,  0.0487,  0.0642,  0.0196,  0.0917,  0.0275,  0.0535,\n",
            "         0.0576,  0.0468, -0.0607, -0.0814,  0.0694, -0.0328, -0.0007,  0.0162,\n",
            "        -0.0429,  0.0490, -0.0008, -0.0170,  0.0042, -0.0943, -0.0388, -0.0059,\n",
            "         0.0554, -0.0111, -0.0413,  0.1003,  0.0589,  0.0399, -0.0332,  0.0062,\n",
            "        -0.0306,  0.0525,  0.0657,  0.0100,  0.0779,  0.0070, -0.0543, -0.0198,\n",
            "         0.0403, -0.0200,  0.0092,  0.0501, -0.0533, -0.0537, -0.0570, -0.1093,\n",
            "         0.0488,  0.0510,  0.0046,  0.0966], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "word :http://t.co/LojgGtGT  \n",
            " encoded : tensor([ 0.0302, -0.0101,  0.0120, -0.0423, -0.0932, -0.0012,  0.0047,  0.0041,\n",
            "         0.0131, -0.0054,  0.0292,  0.0035,  0.0114, -0.0714,  0.0219,  0.0836,\n",
            "        -0.0094,  0.0230, -0.0093, -0.0624,  0.0447, -0.1064, -0.0580,  0.0527,\n",
            "         0.0650,  0.0563,  0.0103, -0.0307,  0.0728,  0.0276, -0.0043, -0.0305,\n",
            "        -0.0860,  0.0026,  0.0090, -0.1024, -0.0037,  0.0052,  0.0520,  0.0116,\n",
            "        -0.0006, -0.0064, -0.0568,  0.0015, -0.0550, -0.1315,  0.0725, -0.0436,\n",
            "        -0.0668, -0.0503, -0.0533,  0.0126,  0.0717, -0.0412,  0.0720, -0.0823,\n",
            "         0.0406,  0.0577,  0.0312,  0.0468, -0.0643, -0.0359,  0.0230, -0.0382,\n",
            "        -0.1033, -0.0114,  0.0874, -0.0473, -0.0281,  0.0051,  0.0089, -0.0149,\n",
            "        -0.0268,  0.0395,  0.0172,  0.0143,  0.0494,  0.0379, -0.0231, -0.0551,\n",
            "        -0.0261, -0.0644,  0.0715,  0.0024,  0.0742, -0.0500,  0.1156,  0.0128,\n",
            "         0.0625,  0.0043, -0.0620, -0.0305, -0.0331, -0.0329,  0.0174, -0.0818,\n",
            "         0.0401,  0.0713,  0.0837,  0.0120], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            " decoded : tensor([ 8.6488e-04, -2.1906e-04, -8.8956e-04, -3.6848e-06,  4.4729e-06,\n",
            "        -2.9765e-06,  4.6570e-05, -8.5805e-05, -5.7902e-06, -6.5258e-05,\n",
            "        -1.3580e-05,  3.1754e-03, -2.3697e-03,  2.8057e-04, -1.2823e-06,\n",
            "        -1.4839e-06, -1.0442e-04, -2.1384e-03,  3.6970e-06,  1.6641e-03,\n",
            "        -3.5741e-04,  4.8109e-05, -7.5194e-04, -6.9292e-06, -1.6120e-06,\n",
            "         2.4659e-03, -1.0209e-04, -2.3958e-03,  2.4646e-03,  7.8308e-04,\n",
            "         1.1597e-03, -1.1635e-05, -8.1843e-06, -1.0766e-05, -1.3508e-03,\n",
            "         2.0237e-04,  5.8144e-06, -3.0012e-06,  9.2249e-05,  4.1475e-05,\n",
            "        -1.8474e-04, -1.1074e-05,  1.6411e-03,  1.3418e-06,  8.5618e-05,\n",
            "         3.8951e-04, -8.1176e-06,  2.4176e-03, -7.9142e-06,  3.5159e-04,\n",
            "        -1.3747e-03, -1.4663e-03,  1.0687e-05,  2.7975e-04,  1.2684e-04,\n",
            "        -2.5091e-04,  7.2940e-05, -7.1573e-04,  3.3188e-04,  3.9482e-04,\n",
            "         3.2768e-04, -1.7875e-03,  3.1395e-06, -2.0149e-04,  1.2024e-04,\n",
            "        -4.6345e-04, -2.6521e-06,  2.3782e-04, -1.8022e-06, -4.7630e-04,\n",
            "         1.1698e-03, -5.8528e-04,  2.3799e-03, -1.8214e-03, -1.2385e-04,\n",
            "        -7.7728e-04,  8.0663e-04,  2.7196e-05,  7.3976e-06, -6.1637e-04,\n",
            "         1.6734e-05,  7.9142e-04,  1.1279e-04, -1.1659e-04, -4.7217e-04,\n",
            "         8.8782e-04, -1.8915e-05,  3.5254e-05,  1.3252e-03, -2.1078e-03,\n",
            "        -3.4700e-08, -4.2385e-05, -1.0852e-03,  7.6807e-04, -2.3950e-06,\n",
            "        -3.2892e-05,  6.6522e-06, -1.2761e-04,  3.3668e-03, -9.2219e-06],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}